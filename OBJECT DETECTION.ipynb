{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import collections\n",
    "from PIL import Image, ImageFont, ImageDraw, ImageEnhance\n",
    "\n",
    "\n",
    "Iterable =  collections.Iterable\n",
    "class PennFudanDataset(object):\n",
    "    def __init__(self, root, transforms):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        # load all image files, sorting them to\n",
    "        # ensure that they are aligned\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"PNGImages\"))))\n",
    "        self.masks = list(sorted(os.listdir(os.path.join(root, \"PedMasks\"))))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images ad masks\n",
    "        img_path = os.path.join(self.root, \"PNGImages\", self.imgs[idx])\n",
    "        mask_path = os.path.join(self.root, \"PedMasks\", self.masks[idx])\n",
    "        img_address = img_path\n",
    "        mask_address = mask_path\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        # note that we haven't converted the mask to RGB,\n",
    "        # because each color corresponds to a different instance\n",
    "        # with 0 being background\n",
    "        mask_pil = Image.open(mask_path)\n",
    "        # convert the PIL Image into a numpy array\n",
    "        mask = np.array(mask_pil)\n",
    "        # instances are encoded as different colors\n",
    "        obj_ids = np.unique(mask)\n",
    "        # first id is the background, so remove it\n",
    "        obj_ids = obj_ids[1:]\n",
    "\n",
    "        # split the color-encoded mask into a set\n",
    "        # of binary masks\n",
    "        masks = mask == obj_ids[:, None, None]\n",
    "\n",
    "        # get bounding box coordinates for each mask\n",
    "        num_objs = len(obj_ids)\n",
    "        boxes = []\n",
    "        for i in range(num_objs):\n",
    "            pos = np.where(masks[i])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "        # convert everything into a torch.Tensor\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        # there is only one class\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        target['mask_pil'] = mask_pil\n",
    "        target['image_address']  = img_address\n",
    "        target['mask_address']  = mask_address\n",
    "        sample={}\n",
    "        sample ['img'] = img\n",
    "        sample['target'] = target\n",
    "        if self.transforms is not None:\n",
    "            sample = self.transforms(sample)\n",
    "            img = sample['img']\n",
    "            \n",
    "            target = sample ['target']\n",
    "            mask_pil_copy = target['mask_pil_copy'] \n",
    "        \n",
    "        target_out={}\n",
    "        target_out['boxes'] = target['boxes']\n",
    "        target_out['labels'] = target['labels']\n",
    "        target_out['masks'] = target['masks']    \n",
    "        return img, target, mask_pil_copy,target_out\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.\n",
    "\n",
    "    Converts a PIL Image or numpy.ndarray (H x W x C) in the range\n",
    "    [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n",
    "    if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1)\n",
    "    or if the numpy.ndarray has dtype = np.uint8\n",
    "\n",
    "    In the other cases, tensors are returned without scaling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Converted image.\n",
    "        \"\"\"\n",
    "        \n",
    "        img = sample['img']\n",
    "        target = sample['target']\n",
    "        \n",
    "        \n",
    "        img = F.to_tensor(img)\n",
    "        masks_pil = F.to_tensor(target['mask_pil'])\n",
    "        #masks_pil_copy = F.to_tensor(target['mask_pil_copy'])\n",
    "        \n",
    "        target['mask_pil'] = masks_pil\n",
    "        #target['mask_pil_copy'] = masks_pil_copy\n",
    "        \n",
    "        sample ['img'] = img\n",
    "        sample['target'] = target\n",
    "        \n",
    "        return sample\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__    \n",
    "    \n",
    "    \n",
    "    \n",
    "class RandomHorizontalFlip(object):\n",
    "    \"\"\"Horizontally flip the given PIL Image randomly with a given probability.\n",
    "\n",
    "    Args:\n",
    "        p (float): probability of the image being flipped. Default value is 0.5\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        img = sample['img']\n",
    "        target = sample ['target']\n",
    "        \n",
    "        img_flipped = F.hflip(img)\n",
    "        \n",
    "        mask_pil = F.hflip (target['mask_pil'])\n",
    "        mask_pil_copy = mask_pil.copy()\n",
    "       \n",
    "        mask = np.array(mask_pil)\n",
    "        # instances are encoded as different colors\n",
    "        obj_ids = np.unique(mask)\n",
    "        # first id is the background, so remove it\n",
    "        obj_ids = obj_ids[1:]\n",
    "\n",
    "        # split the color-encoded mask into a set\n",
    "        # of binary masks\n",
    "        masks = mask == obj_ids[:, None, None]\n",
    "\n",
    "        # get bounding box coordinates for each mask\n",
    "        num_objs = len(obj_ids)\n",
    "        boxes = []\n",
    "        for i in range(num_objs):\n",
    "            pos = np.where(masks[i])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "        c=[]\n",
    "        c.append(0)\n",
    "        c.append(0)\n",
    "        c.append(0)\n",
    "        for i in range(len(obj_ids)*3):\n",
    "                c.append(random.randint(0,255))\n",
    "\n",
    "        mask_pil_copy.putpalette(c)\n",
    "        draw = ImageDraw.Draw(mask_pil_copy)\n",
    "        for i in range(len(boxes)):\n",
    "            draw.rectangle(((boxes[i][0],boxes[i][1]),(boxes[i][2],boxes[i][3])), outline = 128)    \n",
    "\n",
    "        # convert everything into a torch.Tensor\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        # there is only one class\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        target['mask_pil'] = mask_pil\n",
    "        target['mask_pil_copy'] = mask_pil_copy\n",
    "        \n",
    "        sample ['img'] = img_flipped\n",
    "        sample['target'] = target\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to be flipped.\n",
    "\n",
    "        Returns:\n",
    "            PIL Image: Randomly flipped image.\n",
    "        \"\"\"\n",
    "        return sample\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(p={})'.format(self.p)\n",
    "\n",
    "    \n",
    "class Resize(object):\n",
    "    \"\"\"Resize the input PIL Image to the given size.\n",
    "\n",
    "    Args:\n",
    "        size (sequence or int): Desired output size. If size is a sequence like\n",
    "            (h, w), output size will be matched to this. If size is an int,\n",
    "            smaller edge of the image will be matched to this number.\n",
    "            i.e, if height > width, then image will be rescaled to\n",
    "            (size * height / width, size)\n",
    "        interpolation (int, optional): Desired interpolation. Default is\n",
    "            ``PIL.Image.BILINEAR``\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, interpolation=Image.BICUBIC):\n",
    "        assert isinstance(size, int) or (isinstance(size, Iterable) and len(size) == 2)\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to be scaled.\n",
    "\n",
    "        Returns:\n",
    "            PIL Image: Rescaled image.\n",
    "        \"\"\"\n",
    "        \n",
    "        img = sample['img']\n",
    "        target = sample ['target']\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        img_resize = img.resize(self.size)\n",
    "        \n",
    "        mask_pil_resize = target['mask_pil'].resize (self.size)\n",
    "        \n",
    "        mask_pil_copy = mask_pil_resize.copy()\n",
    "        mask = np.array(mask_pil_resize)\n",
    "        # instances are encoded as different colors\n",
    "        obj_ids = np.unique(mask)\n",
    "        # first id is the background, so remove it\n",
    "        obj_ids = obj_ids[1:]\n",
    "\n",
    "        # split the color-encoded mask into a set\n",
    "        # of binary masks\n",
    "        masks = mask == obj_ids[:, None, None]\n",
    "\n",
    "        # get bounding box coordinates for each mask\n",
    "        num_objs = len(obj_ids)\n",
    "        boxes = []\n",
    "        for i in range(num_objs):\n",
    "            pos = np.where(masks[i])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            boxes.append([int(xmin), int(ymin), int(xmax), int(ymax)])\n",
    "\n",
    "        c=[]\n",
    "        c.append(0)\n",
    "        c.append(0)\n",
    "        c.append(0)\n",
    "        for i in range(len(obj_ids)*3):\n",
    "                c.append(random.randint(0,255))\n",
    "\n",
    "        mask_pil_copy.putpalette(c)\n",
    "        draw = ImageDraw.Draw(mask_pil_copy)\n",
    "        for i in range(len(boxes)):\n",
    "            draw.rectangle(((boxes[i][0],boxes[i][1]),(boxes[i][2],boxes[i][3])), outline = 128)    \n",
    "\n",
    "        # convert everything into a torch.Tensor\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        # there is only one class\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        target['mask_pil'] = mask_pil_resize\n",
    "        target['mask_pil_copy'] = mask_pil_copy\n",
    "        sample ['img'] = img_resize\n",
    "        sample['target'] = target\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to be flipped.\n",
    "\n",
    "        Returns:\n",
    "            PIL Image: Randomly flipped image.\n",
    "        \"\"\"\n",
    "        return sample\n",
    "\n",
    "  \n",
    "\n",
    "    def __repr__(self):\n",
    "        interpolate_str = _pil_interpolation_to_str[self.interpolation]\n",
    "        return self.__class__.__name__ + '(size={0}, interpolation={1})'.format(self.size, interpolate_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "from IPython.display import display # to display images\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "   \n",
    "\n",
    "def show_images(sample_batch):\n",
    "    images_batch, target_batch = sample_batch[0], sample_batch[1]\n",
    "    batch_size = len(images_batch)\n",
    "    #im_size = images_batch.size(2)\n",
    "    grid_border_size = 4\n",
    "    grid = utils.make_grid(images_batch)\n",
    "    plt.imsave('images.jpg',grid.numpy().transpose((1,2,0)))\n",
    "\n",
    "def show_masks(sample_batch):\n",
    "    masks  = sample_batch[2]\n",
    "    plt.figure()\n",
    "    for i in range(4):\n",
    "        masks[i].save('mask{}.png'.format(i))\n",
    "        \n",
    "def pallete_segments(maskin):\n",
    "    \n",
    "    test = np.zeros((maskin.shape[1],maskin.shape[2],3))\n",
    "    color_map = []\n",
    "    color_map.append([0,0,0])\n",
    "    for i in (np.unique(maskin)):\n",
    "        color_map.append((np.random.choice(range(256), size=3)))\n",
    "\n",
    "    for i in range(maskin.shape[1]):\n",
    "        for j in range(maskin.shape[2]):\n",
    "            test[i,j] = color_map[maskin[0,i,j]]\n",
    "    return test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    if train:\n",
    "        transforms.append(Resize((300,300)))\n",
    "        transforms.append(RandomHorizontalFlip(0.5))\n",
    "        \n",
    "        \n",
    "    transforms.append(ToTensor())\n",
    "\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "def my_collate(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    target = [item[1] for item in batch]\n",
    "    mask = [item[2] for item in batch]\n",
    "    target_out = [item[3] for item in batch]\n",
    "    return [data, target,mask, target_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PennFudanDataset('/home/ashish95/Pictures/Dataset/PennFudanPed', get_transform(train=True))\n",
    "#dataset_test = PennFudanDataset('/home/ashish95/Pictures/Dataset/PennFudanPed', Trfs)\n",
    "\n",
    "# split the dataset in train and test set\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
    "dataset_test = torch.utils.data.Subset(dataset, indices[-50:])\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4, collate_fn=my_collate)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=False, num_workers=4, collate_fn=my_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ashish95/Pictures/Dataset/PennFudanPed/PNGImages/PennPed00090.png\n",
      "/home/ashish95/Pictures/Dataset/PennFudanPed/PNGImages/PennPed00011.png\n",
      "/home/ashish95/Pictures/Dataset/PennFudanPed/PNGImages/PennPed00079.png\n",
      "/home/ashish95/Pictures/Dataset/PennFudanPed/PNGImages/FudanPed00022.png\n",
      "/home/ashish95/Pictures/Dataset/PennFudanPed/PedMasks/PennPed00090_mask.png\n",
      "/home/ashish95/Pictures/Dataset/PennFudanPed/PedMasks/PennPed00011_mask.png\n",
      "/home/ashish95/Pictures/Dataset/PennFudanPed/PedMasks/PennPed00079_mask.png\n",
      "/home/ashish95/Pictures/Dataset/PennFudanPed/PedMasks/FudanPed00022_mask.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, sample in enumerate(data_loader):\n",
    "        image,target, masks = sample[0] , sample[1] , sample[2]\n",
    "        if i==2:\n",
    "            for j in range(4):\n",
    "                print(target[j]['image_address'])\n",
    "            plt.figure()\n",
    "            show_images(sample)\n",
    "            \n",
    "            plt.figure()\n",
    "            for j in range(4):\n",
    "                print(target[j]['mask_address'])\n",
    "                                \n",
    "            show_masks(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /home/ashish95/.cache/torch/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
      "100%|██████████| 167502836/167502836 [03:59<00:00, 699255.42it/s] \n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "num_classes = 2\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_instance_segmentation(num_classes):\n",
    "    # load an instance segmentation model pre-trained pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
    "                                                       hidden_layer,\n",
    "                                                       num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'boxes': tensor([[162.0173,  97.1730, 171.4453, 115.9252],\n",
      "        [ 75.1344, 137.4904,  82.7737, 159.0323],\n",
      "        [ 84.8555, 130.3780, 130.6535, 142.6487],\n",
      "        [ 87.8385, 129.6041, 116.3362, 136.3241],\n",
      "        [183.3962, 162.7813, 191.6299, 189.1281],\n",
      "        [  4.0828, 130.7319, 102.8573, 156.8064],\n",
      "        [ 87.7609, 139.0770, 112.5542, 167.5904],\n",
      "        [158.8852,  96.7684, 169.2105, 120.2165],\n",
      "        [186.5894, 164.6309, 194.7240, 189.7834],\n",
      "        [ 37.9428, 128.5624,  90.5403, 253.3686],\n",
      "        [ 42.2832, 145.7981,  59.8041, 158.6195],\n",
      "        [ 83.1859, 132.7010,  91.1846, 151.1511],\n",
      "        [  1.9236, 129.5305,  52.1875, 140.5801],\n",
      "        [180.3875, 160.9858, 189.7662, 191.5862],\n",
      "        [ 68.0642, 135.2209,  93.8407, 160.4700],\n",
      "        [ 56.5828, 135.4446, 133.4342, 168.8324],\n",
      "        [ 69.9078, 121.3707,  98.0842, 189.2449],\n",
      "        [179.0718, 164.5763, 209.2260, 193.9974],\n",
      "        [ 88.6800, 131.4789, 116.4250, 140.4637],\n",
      "        [ 54.8546, 133.5273, 100.2065, 145.5180],\n",
      "        [ 68.2302, 134.6509,  88.8438, 179.8001],\n",
      "        [ 48.8909, 134.1121,  97.6485, 179.6672],\n",
      "        [ 95.8508, 141.6793, 103.1089, 175.4491],\n",
      "        [ 99.5396, 141.0690, 106.8764, 176.5023],\n",
      "        [ 75.9691, 131.1034, 116.6889, 144.9914],\n",
      "        [166.5286,  98.8261, 173.9029, 113.7784],\n",
      "        [ 79.7912, 133.8987,  94.9624, 177.4484],\n",
      "        [ 89.4138, 131.8383, 116.4822, 155.7978],\n",
      "        [ 78.1558, 125.5531, 120.7980, 173.3407],\n",
      "        [165.9309, 255.8536, 205.2271, 269.5543],\n",
      "        [ 85.7112, 132.8274, 156.7837, 159.3221],\n",
      "        [ 53.7385, 126.6857, 105.2593, 229.8608],\n",
      "        [ 61.0382, 135.2226,  81.9901, 142.2427],\n",
      "        [162.5255,  67.0526, 168.7180,  75.0520],\n",
      "        [ 32.4978, 125.1695, 136.1172, 147.3547],\n",
      "        [191.5126, 158.8811, 210.7525, 168.5298],\n",
      "        [155.8108,  94.2590, 175.9997, 116.4395],\n",
      "        [119.7775, 249.3552, 227.9205, 272.4861],\n",
      "        [ 73.2038, 137.7670,  80.5774, 154.9716],\n",
      "        [ 87.0330, 132.1664,  94.5909, 147.6399],\n",
      "        [157.0336, 270.0987, 288.5114, 299.8431],\n",
      "        [201.2312, 186.3832, 210.9545, 201.2623],\n",
      "        [  0.0000, 130.9147,  57.2513, 150.5690],\n",
      "        [ 41.1751, 143.2596,  70.9875, 174.0578],\n",
      "        [191.1590, 151.9971, 208.4915, 160.1337],\n",
      "        [189.2175, 158.0636, 235.7320, 173.3162],\n",
      "        [ 84.3493, 133.4931,  95.4718, 139.2020],\n",
      "        [187.9727, 154.4931, 213.8205, 177.3958],\n",
      "        [ 85.1298, 135.3008, 101.1734, 197.1387],\n",
      "        [ 35.8965, 133.9283,  57.3411, 173.4965],\n",
      "        [ 57.3809, 138.1452,  81.4904, 193.0437],\n",
      "        [183.2290, 148.8957, 224.2597, 194.0001],\n",
      "        [ 51.2694, 137.8859,  72.2798, 162.4760],\n",
      "        [182.3818, 155.7089, 202.2579, 202.9577],\n",
      "        [122.3229, 269.1778, 300.0000, 288.3368],\n",
      "        [162.5180,  66.8844, 166.9677,  71.1601],\n",
      "        [155.9899,  84.3508, 169.7342, 140.7731],\n",
      "        [102.3813, 120.6934, 135.0200, 196.9550],\n",
      "        [ 93.0557, 132.8732, 109.5892, 196.9720],\n",
      "        [203.5830, 171.1658, 212.3535, 195.6733],\n",
      "        [161.7296,  63.9480, 165.8346,  68.4422],\n",
      "        [ 85.3378, 131.9619, 142.1730, 182.3925],\n",
      "        [ 79.9169, 133.1391,  94.6924, 148.4209],\n",
      "        [164.3525,  66.1128, 168.8681,  72.7332],\n",
      "        [163.6802,  65.2366, 168.1213,  70.8868],\n",
      "        [ 47.5459, 142.5901,  85.4518, 226.3795],\n",
      "        [ 59.5551, 136.5418,  98.2976, 151.6543],\n",
      "        [ 68.9354, 119.6697, 120.8934, 238.9184],\n",
      "        [ 78.5553, 135.3406, 109.8348, 211.0284],\n",
      "        [104.4471, 149.1166, 111.8459, 172.6896],\n",
      "        [143.4494, 147.0804, 149.5540, 171.4789],\n",
      "        [208.0743, 159.2879, 215.1252, 194.7414],\n",
      "        [ 62.0354, 136.8679,  94.7055, 200.8356],\n",
      "        [ 34.1084, 137.7370,  56.6629, 159.0252],\n",
      "        [ 57.5332, 139.3144,  68.5898, 161.0572],\n",
      "        [160.0598,  64.5733, 164.1268,  68.7783],\n",
      "        [257.8757, 223.4385, 297.1568, 236.9689],\n",
      "        [160.6270,  67.2198, 165.0929,  71.3736],\n",
      "        [ 27.1314, 131.8803,  47.0832, 168.6655],\n",
      "        [102.7118, 136.5974, 117.5490, 195.0082],\n",
      "        [ 10.1492, 129.7387,  57.7694, 168.9258],\n",
      "        [109.4063, 133.5430, 123.7119, 199.2149],\n",
      "        [ 30.0375, 140.2632,  58.8608, 221.5729],\n",
      "        [ 55.8912, 136.7282,  84.2891, 163.0943],\n",
      "        [ 89.5857, 128.3775, 121.6409, 212.9740],\n",
      "        [ 72.3904, 138.8705,  86.7963, 152.7458],\n",
      "        [183.7042, 183.7682, 189.4537, 205.4005],\n",
      "        [192.0619, 155.1174, 212.5042, 193.8713],\n",
      "        [204.1554, 150.1403, 216.0569, 190.4250],\n",
      "        [185.3836, 181.2197, 191.2108, 206.9911],\n",
      "        [183.5644, 150.4629, 216.1580, 169.0100],\n",
      "        [184.6701, 162.5452, 232.4298, 211.1269],\n",
      "        [188.8796, 143.7711, 212.2419, 164.9579],\n",
      "        [ 74.9634, 133.2060,  95.8141, 139.5785],\n",
      "        [ 58.3697, 136.4881,  79.3085, 146.4595],\n",
      "        [169.2655, 149.7432, 247.5358, 176.0207],\n",
      "        [ 60.2133, 138.0215,  76.4900, 152.8156],\n",
      "        [117.5855, 154.3602, 214.7924, 181.2994],\n",
      "        [180.4842, 167.6631, 188.2372, 205.9247],\n",
      "        [ 20.6901, 133.3569,  48.2615, 155.4041]], grad_fn=<StackBackward>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1]), 'scores': tensor([0.6547, 0.6473, 0.6428, 0.6427, 0.6365, 0.6352, 0.6302, 0.6240, 0.6210,\n",
      "        0.6203, 0.6179, 0.6150, 0.6133, 0.6116, 0.6077, 0.6063, 0.6056, 0.6054,\n",
      "        0.6053, 0.6028, 0.6001, 0.6000, 0.5972, 0.5970, 0.5967, 0.5946, 0.5913,\n",
      "        0.5905, 0.5905, 0.5885, 0.5883, 0.5869, 0.5858, 0.5838, 0.5818, 0.5814,\n",
      "        0.5801, 0.5781, 0.5761, 0.5754, 0.5751, 0.5727, 0.5701, 0.5695, 0.5692,\n",
      "        0.5681, 0.5668, 0.5666, 0.5661, 0.5647, 0.5633, 0.5625, 0.5603, 0.5588,\n",
      "        0.5586, 0.5584, 0.5584, 0.5566, 0.5563, 0.5562, 0.5544, 0.5530, 0.5523,\n",
      "        0.5506, 0.5494, 0.5483, 0.5477, 0.5451, 0.5450, 0.5446, 0.5441, 0.5436,\n",
      "        0.5406, 0.5405, 0.5398, 0.5385, 0.5344, 0.5338, 0.5328, 0.5298, 0.5283,\n",
      "        0.5278, 0.5277, 0.5276, 0.5262, 0.5256, 0.5256, 0.5255, 0.5241, 0.5233,\n",
      "        0.5215, 0.5213, 0.5208, 0.5193, 0.5189, 0.5188, 0.5177, 0.5164, 0.5162,\n",
      "        0.5161], grad_fn=<IndexBackward>)}, {'boxes': tensor([[2.2915e+02, 8.1842e+01, 2.7093e+02, 1.4211e+02],\n",
      "        [2.4370e+02, 7.4837e+01, 2.9077e+02, 8.9266e+01],\n",
      "        [2.3641e+02, 6.6643e+01, 2.7976e+02, 1.2892e+02],\n",
      "        [2.3993e+02, 7.2766e+01, 2.7274e+02, 1.1192e+02],\n",
      "        [2.3870e+02, 7.7581e+01, 2.8369e+02, 9.7079e+01],\n",
      "        [2.5119e+02, 7.5776e+01, 2.7595e+02, 1.2870e+02],\n",
      "        [2.4128e+02, 7.7618e+01, 2.6149e+02, 1.3400e+02],\n",
      "        [2.2209e+02, 8.4198e+01, 2.9589e+02, 1.1769e+02],\n",
      "        [1.2679e+02, 8.8707e+01, 1.4523e+02, 1.1614e+02],\n",
      "        [2.0640e+02, 6.7271e+01, 3.0000e+02, 1.2927e+02],\n",
      "        [2.4419e+02, 7.7774e+01, 2.8904e+02, 1.4136e+02],\n",
      "        [2.4101e+02, 8.6825e+01, 2.8568e+02, 1.1040e+02],\n",
      "        [1.2652e+02, 7.2011e+01, 1.4126e+02, 1.2296e+02],\n",
      "        [4.2697e+00, 5.3872e+01, 6.9581e+01, 2.0412e+02],\n",
      "        [1.3215e+02, 8.0024e+01, 2.0660e+02, 1.1249e+02],\n",
      "        [1.3344e+02, 8.9416e+01, 1.4137e+02, 1.1100e+02],\n",
      "        [2.5315e+02, 7.2249e+01, 2.8260e+02, 1.0253e+02],\n",
      "        [1.2410e+02, 8.9855e+01, 1.3944e+02, 1.2877e+02],\n",
      "        [2.3051e+02, 6.4316e+01, 2.5698e+02, 1.7198e+02],\n",
      "        [1.8574e+02, 1.4085e+02, 2.0454e+02, 1.9543e+02],\n",
      "        [2.7049e+02, 7.7901e+01, 2.8583e+02, 1.3065e+02],\n",
      "        [9.6765e+01, 4.8298e+01, 1.0412e+02, 6.0544e+01],\n",
      "        [2.2008e+02, 1.3307e+02, 2.5371e+02, 1.8038e+02],\n",
      "        [2.2516e+02, 7.1980e+01, 3.0000e+02, 1.0172e+02],\n",
      "        [1.3913e+02, 7.5919e+01, 1.9005e+02, 1.3364e+02],\n",
      "        [2.3104e+02, 2.1575e+01, 2.7970e+02, 1.7131e+02],\n",
      "        [1.1930e+02, 6.9339e+01, 1.4285e+02, 1.4531e+02],\n",
      "        [2.8982e+02, 0.0000e+00, 3.0000e+02, 5.1128e+01],\n",
      "        [1.4597e+02, 8.6223e+01, 1.9913e+02, 1.4925e+02],\n",
      "        [1.8374e+02, 8.8770e+01, 3.0000e+02, 1.5887e+02],\n",
      "        [2.6867e+02, 5.8886e+01, 2.9144e+02, 1.8519e+02],\n",
      "        [1.3722e+02, 9.0512e+01, 1.4420e+02, 1.0829e+02],\n",
      "        [1.8008e+02, 7.1761e+00, 1.9702e+02, 3.8088e+01],\n",
      "        [2.2954e+02, 1.3922e+02, 2.4449e+02, 1.8474e+02],\n",
      "        [8.4601e+01, 4.7328e+01, 8.8865e+01, 5.1264e+01],\n",
      "        [1.4267e+02, 3.2044e+01, 1.5829e+02, 6.4966e+01],\n",
      "        [1.3116e+02, 6.3017e+01, 1.4622e+02, 1.1972e+02],\n",
      "        [2.0783e+02, 5.7863e+01, 2.2103e+02, 1.0932e+02],\n",
      "        [2.3144e-01, 7.1594e+01, 3.1248e+01, 2.8591e+02],\n",
      "        [9.5318e+01, 4.6716e+01, 1.0638e+02, 6.3065e+01],\n",
      "        [9.9584e+01, 6.9548e+01, 1.0563e+02, 8.1667e+01],\n",
      "        [2.6215e+02, 7.4433e+01, 2.8410e+02, 1.1660e+02],\n",
      "        [1.4201e+02, 2.7751e+01, 1.8368e+02, 7.2726e+01],\n",
      "        [1.4187e+02, 7.1839e+01, 1.5602e+02, 1.1368e+02],\n",
      "        [9.4106e+01, 7.2288e+01, 1.0580e+02, 8.4405e+01],\n",
      "        [3.8316e+00, 1.6735e+01, 1.0404e+02, 2.4211e+02],\n",
      "        [9.8673e+01, 4.7021e+01, 1.0446e+02, 5.6443e+01],\n",
      "        [2.5103e+02, 2.7295e+01, 2.7403e+02, 5.3251e+01],\n",
      "        [9.4381e+01, 5.1110e+01, 1.0186e+02, 6.4160e+01],\n",
      "        [8.8424e+01, 4.6132e+01, 9.2256e+01, 4.9805e+01],\n",
      "        [1.6024e+02, 2.5097e+02, 1.7332e+02, 2.7735e+02],\n",
      "        [8.5649e+01, 4.6995e+01, 9.1706e+01, 5.0962e+01],\n",
      "        [1.2763e+02, 9.4362e+01, 1.4095e+02, 1.4391e+02],\n",
      "        [9.6088e+01, 4.3463e+01, 1.0572e+02, 5.7186e+01],\n",
      "        [1.2460e+02, 7.3630e+01, 1.6008e+02, 1.2150e+02],\n",
      "        [2.1598e+02, 9.8901e+01, 3.0000e+02, 1.2903e+02],\n",
      "        [8.6954e+01, 4.6376e+01, 9.0979e+01, 4.9787e+01],\n",
      "        [2.3284e+02, 8.4186e+01, 2.4823e+02, 1.4056e+02],\n",
      "        [9.2314e+01, 5.4792e+01, 9.7720e+01, 6.5651e+01],\n",
      "        [2.2478e+02, 1.0786e+02, 2.5190e+02, 2.1618e+02],\n",
      "        [1.9112e+02, 7.2621e+01, 2.0311e+02, 1.5144e+02],\n",
      "        [9.4317e+01, 4.5847e+01, 1.0022e+02, 6.8736e+01],\n",
      "        [1.3191e+02, 8.3106e+01, 1.5255e+02, 1.1071e+02],\n",
      "        [2.1681e+02, 1.1633e+02, 2.4485e+02, 1.9733e+02],\n",
      "        [9.3473e+01, 4.6517e+01, 9.9688e+01, 5.5247e+01],\n",
      "        [8.8199e+01, 4.7072e+01, 9.3099e+01, 5.1157e+01],\n",
      "        [9.7986e+01, 6.9813e+01, 1.0356e+02, 8.3014e+01],\n",
      "        [1.6485e+02, 1.4661e+02, 2.1022e+02, 1.9761e+02],\n",
      "        [1.1047e+02, 8.9781e+01, 2.1641e+02, 1.1566e+02],\n",
      "        [8.0993e+01, 4.8045e+01, 9.1320e+01, 5.2823e+01],\n",
      "        [2.5108e+02, 2.6374e+01, 2.7728e+02, 9.4435e+01],\n",
      "        [1.3551e+02, 5.1930e+01, 1.5131e+02, 1.0668e+02],\n",
      "        [2.2780e+02, 9.3295e+01, 2.7463e+02, 1.7195e+02],\n",
      "        [1.5327e+02, 1.0642e+02, 2.0288e+02, 1.6200e+02],\n",
      "        [5.1759e+01, 5.0305e+01, 9.8748e+01, 9.7105e+01],\n",
      "        [1.2627e+02, 7.1799e+01, 1.4813e+02, 1.7200e+02],\n",
      "        [9.3058e+01, 4.8977e+01, 9.8013e+01, 7.0014e+01],\n",
      "        [2.5455e+02, 6.5266e+01, 2.8226e+02, 1.8684e+02],\n",
      "        [1.7519e+02, 6.2069e+01, 2.0312e+02, 1.7365e+02],\n",
      "        [1.2970e+02, 4.6280e+01, 1.3584e+02, 5.5200e+01],\n",
      "        [9.9990e+01, 7.6395e+01, 1.0617e+02, 8.3357e+01],\n",
      "        [8.5655e+01, 5.3146e+01, 9.1686e+01, 6.2022e+01],\n",
      "        [1.0256e+02, 5.6290e+01, 1.0878e+02, 6.9145e+01],\n",
      "        [2.3019e+02, 1.4418e+02, 2.4013e+02, 1.7369e+02],\n",
      "        [1.8582e+02, 5.6181e+01, 2.7553e+02, 1.9375e+02],\n",
      "        [1.3351e+02, 2.9861e+01, 1.9379e+02, 5.6239e+01],\n",
      "        [1.9187e+02, 1.6095e+01, 3.0000e+02, 1.5569e+02],\n",
      "        [1.2834e+02, 1.0317e+02, 1.3798e+02, 1.2435e+02],\n",
      "        [1.3886e+02, 7.7899e+01, 1.5312e+02, 1.2401e+02],\n",
      "        [9.5416e+01, 6.8407e+01, 1.0206e+02, 8.3943e+01],\n",
      "        [2.6118e+02, 3.4226e+01, 2.9956e+02, 2.4386e+02],\n",
      "        [1.0275e+02, 4.3223e+01, 1.0691e+02, 5.2420e+01],\n",
      "        [1.2660e+02, 1.1762e+02, 2.2584e+02, 1.4927e+02],\n",
      "        [1.6257e+02, 1.6613e+02, 2.0779e+02, 2.1088e+02],\n",
      "        [1.8836e+02, 5.4384e+01, 2.0279e+02, 1.2487e+02],\n",
      "        [7.8700e+01, 4.5593e+01, 9.9250e+01, 6.6166e+01],\n",
      "        [9.1231e+01, 5.5820e+01, 9.6068e+01, 6.4690e+01],\n",
      "        [1.4508e+02, 2.6559e+01, 1.8917e+02, 1.1777e+02],\n",
      "        [1.1492e+02, 8.7055e+01, 1.5102e+02, 1.3173e+02],\n",
      "        [8.9247e+01, 4.4045e+01, 1.0755e+02, 7.0726e+01]],\n",
      "       grad_fn=<StackBackward>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1]), 'scores': tensor([0.7119, 0.7013, 0.6969, 0.6830, 0.6830, 0.6687, 0.6642, 0.6528, 0.6416,\n",
      "        0.6357, 0.6332, 0.6106, 0.6103, 0.6085, 0.6054, 0.6044, 0.6006, 0.5926,\n",
      "        0.5908, 0.5875, 0.5860, 0.5852, 0.5840, 0.5837, 0.5779, 0.5750, 0.5729,\n",
      "        0.5712, 0.5704, 0.5700, 0.5684, 0.5666, 0.5654, 0.5576, 0.5555, 0.5542,\n",
      "        0.5535, 0.5532, 0.5492, 0.5480, 0.5464, 0.5461, 0.5442, 0.5432, 0.5428,\n",
      "        0.5423, 0.5418, 0.5392, 0.5382, 0.5381, 0.5380, 0.5376, 0.5364, 0.5355,\n",
      "        0.5351, 0.5347, 0.5337, 0.5288, 0.5277, 0.5276, 0.5273, 0.5247, 0.5245,\n",
      "        0.5240, 0.5235, 0.5223, 0.5215, 0.5214, 0.5202, 0.5192, 0.5189, 0.5185,\n",
      "        0.5184, 0.5178, 0.5178, 0.5135, 0.5133, 0.5130, 0.5118, 0.5113, 0.5099,\n",
      "        0.5081, 0.5073, 0.5045, 0.5029, 0.5027, 0.5025, 0.5012, 0.5009, 0.5004,\n",
      "        0.5000, 0.4958, 0.4952, 0.4949, 0.4948, 0.4947, 0.4928, 0.4913, 0.4906,\n",
      "        0.4897], grad_fn=<IndexBackward>)}, {'boxes': tensor([[ 22.4127,  88.1812,  56.1314, 133.9220],\n",
      "        [104.8715, 154.9348, 116.3335, 216.1773],\n",
      "        [187.8052, 109.7816, 198.4985, 184.7914],\n",
      "        [ 27.9648,  82.6010,  44.4424, 134.2484],\n",
      "        [100.2761,  62.6288, 111.6076, 127.6187],\n",
      "        [215.7626,  62.3592, 220.5368,  71.5696],\n",
      "        [105.5495,  67.9342, 113.7155,  98.9999],\n",
      "        [ 37.0598,  86.1972,  56.5888, 124.2246],\n",
      "        [121.4948, 229.8469, 135.5730, 264.4856],\n",
      "        [136.3652,  63.8470, 143.3134,  95.7080],\n",
      "        [248.9929,  72.7384, 270.8615, 120.8437],\n",
      "        [203.6508, 101.7838, 215.8346, 166.5891],\n",
      "        [108.0636, 162.4698, 114.6866, 201.6042],\n",
      "        [132.3533,  45.3025, 166.6593, 145.4471],\n",
      "        [202.4503, 105.6270, 212.6158, 197.9688],\n",
      "        [214.3767,  61.1539, 219.2018,  70.6277],\n",
      "        [184.7707, 122.5114, 196.5274, 201.0113],\n",
      "        [ 94.7736,  63.0399, 107.2107, 129.0305],\n",
      "        [241.9779,  84.2199, 259.6626, 120.9844],\n",
      "        [285.1002,  29.5390, 290.7095,  45.6707],\n",
      "        [186.0579, 152.8660, 198.3685, 196.2547],\n",
      "        [ 54.0357, 191.7891,  65.1736, 229.4670],\n",
      "        [240.4226,  73.4388, 268.1283, 140.2755],\n",
      "        [ 56.1238, 230.2343, 136.1318, 255.1763],\n",
      "        [220.3170,  76.5732, 227.4362, 105.9341],\n",
      "        [132.8658,  63.1576, 140.7154,  95.0516],\n",
      "        [ 10.8345, 239.5656, 152.4411, 256.1707],\n",
      "        [194.7590, 111.4195, 207.0777, 193.1114],\n",
      "        [180.1449, 114.6455, 193.4223, 187.2355],\n",
      "        [136.1666,  51.7378, 153.7474, 106.9095],\n",
      "        [ 61.0606,  39.8962,  73.7699,  86.7181],\n",
      "        [217.9281,  61.8226, 229.6811, 133.1985],\n",
      "        [168.9506,  89.3800, 172.1786,  93.3677],\n",
      "        [101.5402, 149.7841, 109.6107, 221.2023],\n",
      "        [ 65.1354,  53.3375,  71.0411,  77.3176],\n",
      "        [104.9559, 160.7056, 196.3571, 187.0470],\n",
      "        [104.8706,  68.1990, 110.7846,  91.0097],\n",
      "        [ 53.5739,  48.1724,  70.9595, 101.6033],\n",
      "        [ 55.1043, 205.3937,  63.0166, 223.4898],\n",
      "        [132.3765,  51.0394, 144.1003, 110.5791],\n",
      "        [263.8942,  34.2860, 281.1186,  74.8237],\n",
      "        [223.3917,  82.9322, 239.1664, 121.8064],\n",
      "        [213.9519,  55.8950, 218.7088,  67.3974],\n",
      "        [ 27.6444,  66.6236,  37.5543, 120.8131],\n",
      "        [ 23.2910, 200.9279, 136.3368, 224.4309],\n",
      "        [220.0669,  72.2843, 232.0192, 116.4368],\n",
      "        [197.8310, 100.7433, 210.7983, 168.6771],\n",
      "        [216.9700, 177.0911, 225.0587, 205.5792],\n",
      "        [182.4361, 157.8780, 227.2607, 203.4796],\n",
      "        [ 33.0144,  41.6513,  75.0594, 121.0766],\n",
      "        [244.2325,  58.0912, 289.5724, 271.4246],\n",
      "        [114.7416, 227.5230, 129.8547, 255.1062],\n",
      "        [187.6431,  82.1225, 208.6446, 212.2345],\n",
      "        [101.3534, 162.3224, 107.4654, 201.4287],\n",
      "        [106.4641,  65.8324, 111.7919,  82.2052],\n",
      "        [ 99.9992, 103.9561, 111.3077, 179.5671],\n",
      "        [ 46.8618,  49.0893,  64.7214,  92.8732],\n",
      "        [243.5268,  90.7983, 279.3344, 114.4974],\n",
      "        [191.5079, 102.2609, 196.8965, 108.3339],\n",
      "        [105.2091,  56.8578, 119.6469, 111.5917],\n",
      "        [ 38.1710,  48.6952,  57.1011,  98.8927],\n",
      "        [220.4313, 178.6415, 227.0495, 204.8497],\n",
      "        [  3.0162, 244.1365, 161.7420, 262.3794],\n",
      "        [100.9408, 113.8192, 109.7638, 145.4234],\n",
      "        [248.3388,  93.6654, 259.2882, 118.1364],\n",
      "        [ 44.7160, 205.2154, 117.0280, 217.7159],\n",
      "        [221.7587,  87.7044, 229.4847, 109.6133],\n",
      "        [191.4971, 106.6408, 202.8137, 174.7106],\n",
      "        [223.0119, 175.4845, 229.2445, 204.9679],\n",
      "        [179.0306, 131.8586, 202.1586, 208.1352],\n",
      "        [122.0128, 100.9005, 233.4827, 233.9523],\n",
      "        [126.7160,  49.5911, 141.1283, 100.0501],\n",
      "        [131.0880,  56.2792, 152.4931,  88.9272],\n",
      "        [247.7768, 198.6418, 253.8121, 206.4574],\n",
      "        [167.6698,  90.0011, 170.5509,  94.5653],\n",
      "        [103.9652, 135.9387, 195.8271, 166.7220],\n",
      "        [ 87.1662,  44.1037, 112.0980, 173.9124],\n",
      "        [223.8805,  86.8863, 248.0436, 112.4712],\n",
      "        [ 66.3381,  46.9057,  70.1982,  64.0288],\n",
      "        [ 48.9612,  44.6166, 119.4216, 161.3244],\n",
      "        [189.2597, 148.2499, 205.4691, 204.3238],\n",
      "        [ 83.7623, 239.3002, 129.6323, 255.9846],\n",
      "        [104.2182, 162.6482, 110.4671, 199.9339],\n",
      "        [103.5796,  63.2296, 115.5089, 123.6393],\n",
      "        [171.0118,  47.0627, 180.4754,  73.2267],\n",
      "        [ 27.5567, 204.0254,  67.6920, 220.3022],\n",
      "        [ 22.9765,  59.1457,  52.0931, 165.7495],\n",
      "        [181.4760, 137.1403, 245.5842, 292.0507],\n",
      "        [174.4594, 143.4276, 190.9345, 208.5483],\n",
      "        [228.6784,  74.9616, 275.9948, 119.9522],\n",
      "        [189.6964, 100.6134, 194.6164, 108.9270],\n",
      "        [193.6527, 169.2008, 224.4097, 297.2693],\n",
      "        [224.7227, 177.9800, 233.6362, 201.0673],\n",
      "        [206.9736, 206.4576, 300.0000, 300.0000],\n",
      "        [168.1381,  88.2354, 171.7521,  94.6398],\n",
      "        [ 45.1707, 200.6188, 113.8607, 212.1858],\n",
      "        [221.4883,  63.0179, 248.3220, 146.1069],\n",
      "        [168.8550,  90.3742, 171.7999,  96.0099],\n",
      "        [217.7166,  36.9497, 279.5754, 100.2760],\n",
      "        [ 27.5231, 128.4368, 248.9414, 187.2114]], grad_fn=<StackBackward>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1]), 'scores': tensor([0.6633, 0.6429, 0.6282, 0.6206, 0.6168, 0.6096, 0.6000, 0.5962, 0.5949,\n",
      "        0.5949, 0.5904, 0.5896, 0.5849, 0.5846, 0.5791, 0.5761, 0.5760, 0.5737,\n",
      "        0.5714, 0.5706, 0.5692, 0.5659, 0.5656, 0.5631, 0.5606, 0.5605, 0.5590,\n",
      "        0.5583, 0.5576, 0.5574, 0.5567, 0.5559, 0.5556, 0.5551, 0.5537, 0.5527,\n",
      "        0.5516, 0.5487, 0.5462, 0.5459, 0.5452, 0.5449, 0.5426, 0.5390, 0.5382,\n",
      "        0.5378, 0.5360, 0.5351, 0.5350, 0.5328, 0.5277, 0.5274, 0.5271, 0.5266,\n",
      "        0.5263, 0.5258, 0.5254, 0.5250, 0.5236, 0.5223, 0.5222, 0.5180, 0.5164,\n",
      "        0.5142, 0.5138, 0.5132, 0.5124, 0.5109, 0.5105, 0.5091, 0.5090, 0.5081,\n",
      "        0.5077, 0.5072, 0.5062, 0.5061, 0.5047, 0.5042, 0.5037, 0.5033, 0.5030,\n",
      "        0.5030, 0.5024, 0.5020, 0.5008, 0.5002, 0.5001, 0.5001, 0.4998, 0.4996,\n",
      "        0.4980, 0.4975, 0.4971, 0.4970, 0.4963, 0.4949, 0.4946, 0.4937, 0.4919,\n",
      "        0.4917], grad_fn=<IndexBackward>)}, {'boxes': tensor([[121.0617,  69.8635, 126.5098, 110.6239],\n",
      "        [124.7372,  66.7578, 138.4950, 141.9546],\n",
      "        [122.9293,  67.3071, 127.9572, 111.6576],\n",
      "        [118.2578,  67.2518, 124.9807, 110.1060],\n",
      "        [253.2808, 100.7472, 299.8600, 135.2320],\n",
      "        [125.1395,  67.8471, 130.5881, 108.8170],\n",
      "        [119.8655,  58.8496, 130.1564, 126.7339],\n",
      "        [ 66.0708,  70.1333,  73.3132,  93.3140],\n",
      "        [ 61.7971,  71.7537,  69.8740,  92.5301],\n",
      "        [ 69.4252,  71.9976,  75.1434,  92.2127],\n",
      "        [ 60.2382,  68.8325,  68.1066, 100.7253],\n",
      "        [112.9048, 118.6182, 119.9251, 125.5540],\n",
      "        [254.9428,  96.6950, 297.9026, 193.4065],\n",
      "        [ 59.7084,  69.9304,  65.8851,  90.9142],\n",
      "        [ 72.1092,  73.3387,  76.8745,  93.2990],\n",
      "        [ 52.2260,  61.2457,  66.9395, 126.8423],\n",
      "        [123.5288,  59.4355, 134.0952, 124.0247],\n",
      "        [119.8059,  71.5613, 133.7328, 144.1021],\n",
      "        [ 63.6428,  65.5559,  69.6461,  78.5668],\n",
      "        [119.4634,  83.2236, 126.8186, 119.6426],\n",
      "        [207.5490,  93.9127, 300.0000, 162.9731],\n",
      "        [ 70.1230,  67.4686,  74.4154,  86.4565],\n",
      "        [112.8731,  74.6954, 129.1789, 136.1786],\n",
      "        [116.8745,  81.9746, 123.9991, 118.4409],\n",
      "        [128.8761,  73.0017, 141.4485, 158.6265],\n",
      "        [ 60.9532,  66.5330,  66.4493,  83.9291],\n",
      "        [ 94.3589,  89.1792, 103.9587, 112.7555],\n",
      "        [ 62.7918,  68.3169,  68.7006,  84.8681],\n",
      "        [ 65.1942,  70.3359,  71.1075,  85.9934],\n",
      "        [ 35.4922, 132.3515,  49.9283, 160.5291],\n",
      "        [112.0953,  59.4082, 126.8839, 117.3084],\n",
      "        [ 65.1471,  67.4838,  70.1036,  74.4939],\n",
      "        [ 57.4058,  69.4300,  64.3362, 100.1135],\n",
      "        [ 73.6133, 106.4795,  81.5714, 111.3111],\n",
      "        [ 51.4509,  58.4764,  70.3907,  98.6408],\n",
      "        [ 68.3338,  68.7583,  73.2445,  86.4848],\n",
      "        [ 37.7645, 133.7017,  47.2567, 153.2676],\n",
      "        [106.1885, 114.6221, 122.2450, 127.8168],\n",
      "        [ 65.9208,  65.7914,  71.2113,  79.8254],\n",
      "        [103.5101,  65.0742, 123.9995, 124.8921],\n",
      "        [  7.2624, 108.8487, 113.9418, 130.2561],\n",
      "        [ 62.4427,  59.0948,  69.1315,  71.2204],\n",
      "        [130.8085,  66.3310, 300.0000, 171.1310],\n",
      "        [110.9210, 120.0379, 116.9311, 126.3710],\n",
      "        [279.6303, 112.6547, 300.0000, 289.8336],\n",
      "        [ 61.9392,  65.0924,  67.0027,  76.0221],\n",
      "        [ 89.3562, 268.2735, 130.1789, 273.1009],\n",
      "        [104.3658,  59.3948, 118.5669, 110.7497],\n",
      "        [ 53.9372,  62.4110,  73.9540,  88.0532],\n",
      "        [ 59.5346,  62.2107,  78.5327, 122.0941],\n",
      "        [  7.7079,  67.1081,  58.0318, 131.7067],\n",
      "        [ 79.8757,  54.3280, 217.5029,  80.7308],\n",
      "        [133.3624, 136.8724, 139.9556, 154.7752],\n",
      "        [131.2889, 136.5597, 136.2563, 143.0815],\n",
      "        [ 79.4501, 104.9680,  85.7111, 108.9033],\n",
      "        [ 34.6758,  17.4030, 300.0000, 173.9380],\n",
      "        [139.1651, 110.2800, 154.2019, 171.2992],\n",
      "        [139.0130, 154.7741, 150.3854, 180.1606],\n",
      "        [ 62.4949,  67.3906,  73.1348,  82.6515],\n",
      "        [ 78.0404, 106.2986,  83.0672, 110.5689],\n",
      "        [235.8450,  48.1758, 294.2309, 187.4007],\n",
      "        [ 88.7313,  97.3096, 103.3405, 112.4254],\n",
      "        [ 79.1616, 112.4642, 171.1236, 136.9414],\n",
      "        [ 64.2859,  64.0885,  70.2490,  72.9929],\n",
      "        [102.2839, 111.3596, 118.3052, 128.4789],\n",
      "        [132.7752, 131.6821, 137.5288, 137.2363],\n",
      "        [ 60.9776,  54.3467,  77.0739,  97.3884],\n",
      "        [ 96.9291, 114.2590, 140.6319, 129.3865],\n",
      "        [132.8265, 135.6619, 137.3505, 142.6331],\n",
      "        [132.8398, 133.3518, 137.4696, 139.3896],\n",
      "        [269.5101,  96.7463, 300.0000, 120.6266],\n",
      "        [ 79.4269,  47.1760, 203.2181,  70.8016],\n",
      "        [ 10.1619, 149.3220,  24.1387, 165.1352],\n",
      "        [101.1354, 109.3761, 126.9922, 130.6641],\n",
      "        [ 59.9236,  64.7144,  70.6621,  77.4074],\n",
      "        [ 99.1235,  66.1325, 111.2911, 125.0452],\n",
      "        [  4.4817, 146.4645,  26.9456, 169.2163],\n",
      "        [ 81.0086, 103.3824,  88.9118, 107.5789],\n",
      "        [137.1860, 134.2711, 142.7219, 158.1812],\n",
      "        [ 76.9825, 107.3351,  81.7111, 111.4564],\n",
      "        [131.6932, 137.6446, 138.5073, 148.2254],\n",
      "        [ 61.0794,  56.7265,  66.0573,  69.4921],\n",
      "        [ 11.1616,  35.2607, 256.0834,  80.2236],\n",
      "        [281.4157,  95.4503, 300.0000, 214.2177],\n",
      "        [ 81.5086, 104.8745,  88.7352, 108.6202],\n",
      "        [194.3302,  47.9975, 285.0247, 202.7872],\n",
      "        [133.7242, 112.7141, 155.5306, 216.2177],\n",
      "        [ 79.8288, 105.5029,  87.6334, 110.2568],\n",
      "        [128.3127, 134.0409, 133.8101, 139.1893],\n",
      "        [ 73.8961, 265.4941, 155.2104, 273.7803],\n",
      "        [ 48.0757, 265.7909, 191.2383, 280.9106],\n",
      "        [ 34.3794, 152.9986,  49.4016, 166.3598],\n",
      "        [147.8954, 154.9340, 155.0073, 178.3880],\n",
      "        [130.9279, 136.3579, 140.0384, 165.4552],\n",
      "        [ 78.1454,  97.2967,  92.6401, 110.8042],\n",
      "        [ 76.8009,  49.3397, 113.1346, 176.0074],\n",
      "        [123.0543,  92.8484, 139.6250, 155.5402],\n",
      "        [102.6555,  83.7290, 147.8192, 150.1344],\n",
      "        [ 62.7242,  71.9793, 106.7892, 123.9624],\n",
      "        [129.9583, 132.1439, 134.5666, 137.0013]], grad_fn=<StackBackward>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1]), 'scores': tensor([0.7033, 0.6802, 0.6796, 0.6761, 0.6651, 0.6577, 0.6564, 0.6522, 0.6490,\n",
      "        0.6463, 0.6290, 0.6271, 0.6253, 0.6246, 0.6214, 0.6211, 0.6131, 0.6125,\n",
      "        0.6103, 0.6069, 0.6045, 0.6020, 0.6016, 0.6013, 0.6004, 0.5994, 0.5988,\n",
      "        0.5987, 0.5986, 0.5981, 0.5980, 0.5976, 0.5938, 0.5928, 0.5896, 0.5896,\n",
      "        0.5885, 0.5858, 0.5838, 0.5796, 0.5772, 0.5772, 0.5756, 0.5740, 0.5730,\n",
      "        0.5717, 0.5709, 0.5644, 0.5629, 0.5629, 0.5628, 0.5622, 0.5608, 0.5572,\n",
      "        0.5568, 0.5531, 0.5529, 0.5511, 0.5505, 0.5490, 0.5465, 0.5461, 0.5409,\n",
      "        0.5345, 0.5343, 0.5322, 0.5320, 0.5314, 0.5313, 0.5312, 0.5310, 0.5292,\n",
      "        0.5285, 0.5264, 0.5255, 0.5248, 0.5232, 0.5215, 0.5210, 0.5204, 0.5194,\n",
      "        0.5175, 0.5149, 0.5135, 0.5133, 0.5110, 0.5108, 0.5098, 0.5097, 0.5096,\n",
      "        0.5090, 0.5086, 0.5085, 0.5069, 0.5021, 0.5011, 0.5009, 0.4990, 0.4972,\n",
      "        0.4970], grad_fn=<IndexBackward>)}]\n"
     ]
    }
   ],
   "source": [
    "num_epochs=1\n",
    "for i in range (num_epochs):\n",
    "    for i,sample in enumerate(data_loader):\n",
    "        image,target_in,mask,target_out = sample[0],sample[1],sample[2],sample[3]\n",
    "        model.eval()\n",
    "        predictions = model(image,target_out)\n",
    "        print(predictions)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
