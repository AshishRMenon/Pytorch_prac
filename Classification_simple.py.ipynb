{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "transform=T.Compose([T.ToTensor(), T.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "\n",
    "traindata=torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform)\n",
    "trainloader=torch.utils.data.DataLoader(traindata, batch_size=4, shuffle=True)\n",
    "\n",
    "testdata=torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
    "testloader=torch.utils.data.DataLoader(testdata, batch_size=4, shuffle=True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imgshow(image):\n",
    "    image=image*0.5 + 0.5\n",
    "    img_np = image.numpy()\n",
    "    plt.imsave('sample.jpg', np.transpose(img_np,(1,2,0)))\n",
    "\n",
    "image,labels=iter(trainloader).next()\n",
    "imgshow(torchvision.utils.make_grid(image))\n",
    "print( [classes[labels[j]] for j in range(4)])\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network,self).__init__()\n",
    "        self.cnv1=nn.Conv2d(3,6,5)\n",
    "        self.pool=nn.MaxPool2d(2,2)\n",
    "        self.cnv2=nn.Conv2d(6,16,5)\n",
    "        self.fc1=nn.Linear(400,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3=nn.Linear(84,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.cnv1(x)))\n",
    "        x = self.pool(F.relu(self.cnv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "net=Network()\n",
    "import torch.optim as optim\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.SGD(net.parameters() , lr=0.001, momentum=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def imageshow(im):\n",
    "    im_np= im.numpy()\n",
    "    im_np= np.transpose(im_np, (1,2,0))\n",
    "    im_np=im_np*0.5 + 0.5 \n",
    "    plt.imshow(im_np)\n",
    "images,labels = iter(trainloader).next()\n",
    "images=torchvision.utils.make_grid(images)\n",
    "imageshow(images)\n",
    "#images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    running_loss=0\n",
    "    for i,data in enumerate(trainloader):\n",
    "        images,labels=data\n",
    "        optimizer.zero_grad()\n",
    "        output = net(images)\n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "correct=0\n",
    "recall=[]\n",
    "total=0\n",
    "classes_ref=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "classes_total=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        image,labels=data\n",
    "        y_true = labels.view(-1).numpy()\n",
    "        output_test=net(image)\n",
    "        _, predictions = torch.max(output_test,1)\n",
    "        total+=labels.size(0)\n",
    "        y_pred = predictions.view(-1).numpy()\n",
    "        correct+=(predictions==labels).sum().item()\n",
    "        recall.append(recall_score(list(y_true), list(y_pred), average='macro'))\n",
    "        for i in range(4):\n",
    "            if predictions[i]==labels[i]:\n",
    "                classes_ref[np.int(predictions[i].numpy())]+=1\n",
    "            classes_total[labels[i]]+=1\n",
    "\n",
    "    print('Accuracy={}%'.format(100*correct/total))\n",
    "    print('Recall ={} '.format(np.mean(recall)))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (10):\n",
    "    print('Accuracy of {} = {}'.format(classes[i],classes_ref[i]/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets,models,transforms\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from skimage import io\n",
    "import pathlib\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\"\"\"\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('-l','--filelist', nargs='+', help='<Required> Set flag', required=True)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\"\"\"\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "\n",
    "\n",
    "ngpu=4\n",
    "\n",
    "root='/ssd_scratch/cvit/ashish/kidney/'\n",
    "\n",
    "T = {'train': transforms.Compose([ transforms.RandomResizedCrop(224),\n",
    "                                   transforms.RandomHorizontalFlip(),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0.596, 0.436, 0.586], [0.2066, 0.240, 0.186])       \n",
    "                                 ]) ,\n",
    "      \n",
    "    'val': transforms.Compose([   transforms.Resize(224),\n",
    "                                   transforms.RandomHorizontalFlip(),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0.596, 0.436, 0.586], [0.2066, 0.240, 0.186])       \n",
    "                                 ]) ,\n",
    "      \n",
    "    'test': transforms.Compose([ transforms.Resize(224),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0.596, 0.436, 0.586], [0.2066, 0.240, 0.186])       \n",
    "                                 ]) \n",
    "    }\n",
    "\n",
    "datasets={x: datasets.ImageFolder( os.path.join(root,x), T[x] ) for x in ['test'] }\n",
    "dataloaders={x : torch.utils.data.DataLoader(datasets[x] , shuffle=True, batch_size=128 , num_workers=4) for x in ['test']}\n",
    "datalength= { x : len(datasets[x]) for x in ['test']}\n",
    "print(datalength['test'])\n",
    "device=torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "class_names=datasets['test'].classes\n",
    "print(class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer\n"
     ]
    }
   ],
   "source": [
    "t=[1,0,0,0,0,0,0,0,0,0,0 ]\n",
    "if 1 in t:\n",
    "    print('cancer')\n",
    "    \n",
    "    \n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets,models,transforms\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from skimage import io\n",
    "import pathlib\n",
    "\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\"\"\"\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('-l','--filelist', nargs='+', help='<Required> Set flag', required=True)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--load')\n",
    "parser.add_argument('--savemodel')\n",
    "parser.add_argument('--dataroot')\n",
    "parser.add_argument('--ngpu')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "g=args.load\n",
    "print(g)\n",
    "fg=pathlib.Path(g)\n",
    "\n",
    "s=args.savemodel\n",
    "print(s)\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "\n",
    "\n",
    "ngpu=args.ngpu\n",
    "\n",
    "root = args.dataroot\n",
    "\n",
    "T = {'train': transforms.Compose([ transforms.RandomResizedCrop(224),\n",
    "                                   transforms.RandomHorizontalFlip(),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0.596, 0.436, 0.586], [0.2066, 0.240, 0.186])       \n",
    "                                 ]) ,\n",
    "      \n",
    "    'valid': transforms.Compose([   transforms.Resize(224),\n",
    "                                   transforms.RandomHorizontalFlip(),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0.596, 0.436, 0.586], [0.2066, 0.240, 0.186])       \n",
    "                                 ]) ,\n",
    "      \n",
    "    'test': transforms.Compose([ transforms.RandomHorizontalFlip(),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))       \n",
    "                                 ]) \n",
    "    }\n",
    "\n",
    "datasets={x: datasets.ImageFolder( os.path.join(root,x), T[x] ) for x in os.listdir(root) }\n",
    "dataloaders={x : torch.utils.data.DataLoader(datasets[x] , shuffle=True, batch_size=128 , num_workers=4) for x in os.listdir(root)}\n",
    "datalength= { x : len(datasets[x]) for x in os.listdir(root)}\n",
    "print(datalength['train'])\n",
    "print(datalength['valid'])\n",
    "device=torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "class_names=datasets['train'].classes\n",
    "print(class_names)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def imgshow(img):\n",
    "    im=img.numpy().transpose((1,2,0))\n",
    "    mean = np.array([0.596, 0.436, 0.586])\n",
    "    std = np.array([0.2066, 0.240, 0.186])\n",
    "    im=im*std + mean\n",
    "    plt.imsave('images.jpg',im)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "images,labels= iter(dataloaders['train']).next()\n",
    "images=torchvision.utils.make_grid(images)\n",
    "imgshow(images)\n",
    "\"\"\"\n",
    "lst=os.listdir(root)\n",
    "acc_list=[]\n",
    "loss_list=[]\n",
    "epoch_list=[]\n",
    "#lst=lst.sort()\n",
    "print(lst)\n",
    "def train_model(model, criterion, optimizer, scheduler , num_epochs=10):\n",
    "    since=time.time()\n",
    "    best_model_wts=copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('-'*10 + ' Epoch {}'.format(epoch) + '-'*10, flush=True)\n",
    "            \n",
    "        for phase in ['train', 'valid']:\n",
    "            print(phase,flush=True)\n",
    "            if phase=='train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            running_loss=0\n",
    "            running_corrects=0\n",
    "            try:\n",
    "                for images , labels in dataloaders[phase]:\n",
    "                    images=images.to(device)\n",
    "                    labels=labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    with torch.set_grad_enabled(phase=='train'):\n",
    "\n",
    "                        outputs=model(images)\n",
    "                        _,predictions=torch.max(outputs,1)\n",
    "                        loss=criterion(outputs,labels)\n",
    "                        if phase=='train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                    running_loss+=loss.item()*images.size(0)\n",
    "                    running_corrects+=torch.sum(predictions == labels.data)\n",
    "                epoch_loss=running_loss/datalength[phase]\n",
    "                epoch_acc=running_corrects.double()/datalength[phase]\n",
    "                if phase=='train':\n",
    "                \tscheduler.step(epoch_loss)\n",
    "                acc_list.append(epoch_acc)\n",
    "                loss_list.append(epoch_loss)\n",
    "                epoch_list.append(epoch)\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc),flush=True)\n",
    "\n",
    "\n",
    "                if phase == 'valid' and epoch_acc>best_acc:\n",
    "                    best_acc=epoch_acc\n",
    "                    best_model_wts=copy.deepcopy(model.state_dict())\n",
    "            except Exception as e:\n",
    "               print('exception occured',e,flush=True)\n",
    "    model.load_state_dict(best_model_wts)    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "d='/home/ashishmenon/openslide_WSI/synth_pretraining/pretrained_KIRP.pth'\n",
    "\n",
    "fd=pathlib.Path(d)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if (fg.exists ()):\n",
    "    print('Loading Model', flush=True)\n",
    "    model_ft = model_ft.to(device)\n",
    "    if (device.type == 'cuda') and (ngpu > 1):\n",
    "        model_ft = nn.DataParallel(model_ft, list(range(ngpu)))\n",
    "    model_ft.load_state_dict(torch.load(d))\n",
    "    print('Model Loaded', flush=True)\n",
    "\n",
    "\n",
    "if (not(fg.exists ())):\n",
    "\n",
    "    model_ft = model_ft.to(device)\n",
    "    if (device.type == 'cuda') and (ngpu > 1):\n",
    "    model_ft = nn.DataParallel(model_ft, list(range(ngpu)))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.00005, weight_decay=0.05)\n",
    "exp_lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, 'min', patience=2, verbose=True, factor = 0.2)\n",
    "\n",
    "\n",
    "\n",
    "model_conv = train_model(model_ft, criterion, optimizer_ft,exp_lr_scheduler, num_epochs=25)\n",
    "torch.save(model_conv.state_dict(),s)\n",
    "\n",
    "plt.plot(epoch_list,acc_list)\n",
    "plt.savefig('acc.jpg')\n",
    "\n",
    "\n",
    "plt.plot(epoch_list,loss_list)\n",
    "plt.savefig('loss.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
