{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -l FILELIST [FILELIST ...]\n",
      "ipykernel_launcher.py: error: the following arguments are required: -l/--filelist\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashish95/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets,models,transforms\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('-l','--filelist', nargs='+', help='<Required> Set flag', required=True)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "T = {'train': transforms.Compose([ transforms.RandomHorizontalFlip(),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))       \n",
    "                                 ]) ,\n",
    "      \n",
    "    'test': transforms.Compose([ transforms.RandomHorizontalFlip(),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))       \n",
    "                                 ]) ,\n",
    "      \n",
    "    'valid': transforms.Compose([ transforms.RandomHorizontalFlip(),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))       \n",
    "                                 ]) \n",
    "    }\n",
    "\n",
    "datasets={x: datasets.ImageFolder( os.path.join(root,x), T[x] ) for x in args.filelist }\n",
    "dataloaders={x : torch.utils.data.DataLoader(datasets[x] , shuffle=True, batch_size=4 , num_workers=2) for x in args.filelist}\n",
    "datalength= { x : len(datasets_reqd[x]) for x in args.filelist}\n",
    "device=torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "class_names=datasets_reqd['train'].classes\n",
    "print(classes_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets,models,transforms\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training( model , scheduler , optimizer, criterion):\n",
    "    best_acc=0\n",
    "    best_model_wts= copy.deepcopy(model.state_dict())\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        for phase in args.filelist:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            running_loss=0\n",
    "            running_corrects=0\n",
    "            for images,labels in dataloaders[phase]:\n",
    "            \n",
    "                images=images.to(device)\n",
    "                labels=labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase=='Train'):\n",
    "                    output = model(images)\n",
    "                    _,predictions=torch.max(outputs,1)\n",
    "                    loss = criterion(outputs,labels)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss = loss.item()*images.size(0)\n",
    "                running_corrects= torch.sum(predictions==labels.data)\n",
    "            epoch_loss=running_loss/datalength[phase]\n",
    "            epoch_acc=running_corrects.double()/datalength[phase]\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            \n",
    "            if phase=='val' and epoch_acc>best_acc:\n",
    "                best_acc=epoch_acc\n",
    "                best_model_wts=copy.deepcopy(model.state_dict())\n",
    "    model.load_state_dict(best_model_wts)    \n",
    "    return model\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "\n",
    "model_conv = train_model(model_conv, criterion, optimizer_ft,exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train', 'val']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets,models,transforms\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from skimage import io\n",
    "import pathlib\n",
    "\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\"\"\"\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('-l','--filelist', nargs='+', help='<Required> Set flag', required=True)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\"\"\"\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "\n",
    "\n",
    "ngpu=2\n",
    "\n",
    "root='/ssd_scratch/cvit/ashish/kidney/'\n",
    "\n",
    "T = {'train': transforms.Compose([ transforms.RandomResizedCrop(224),\n",
    "                                   transforms.RandomHorizontalFlip(),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0.596, 0.436, 0.586], [0.2066, 0.240, 0.186])       \n",
    "                                 ]) ,\n",
    "      \n",
    "    'val': transforms.Compose([   transforms.Resize(224),\n",
    "                                   transforms.RandomHorizontalFlip(),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0.596, 0.436, 0.586], [0.2066, 0.240, 0.186])       \n",
    "                                 ]) ,\n",
    "      \n",
    "    'test': transforms.Compose([ transforms.Resize(224),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0.596, 0.436, 0.586], [0.2066, 0.240, 0.186])       \n",
    "                                 ]) \n",
    "    }\n",
    "\n",
    "datasets={x: datasets.ImageFolder( os.path.join(root,x), T[x] ) for x in ['test'] }\n",
    "dataloaders={x : torch.utils.data.DataLoader(datasets[x] , shuffle=True, batch_size=128 , num_workers=4) for x in ['test']}\n",
    "datalength= { x : len(datasets[x]) for x in ['test']}\n",
    "print(datalength['test'])\n",
    "device=torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "class_names=datasets['test'].classes\n",
    "print(class_names)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def imgshow(img):\n",
    "    im=img.numpy().transpose((1,2,0))\n",
    "    mean = np.array([0.596, 0.436, 0.586])\n",
    "    std = np.array([0.2066, 0.240, 0.186])\n",
    "    im=im*std + mean\n",
    "    plt.imsave('images.jpg',im)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "images,labels= iter(dataloaders['train']).next()\n",
    "images=torchvision.utils.make_grid(images)\n",
    "imgshow(images)\n",
    "\"\"\"\n",
    "lst=['test']\n",
    "acc_list=[]\n",
    "loss_list=[]\n",
    "epoch_list=[]\n",
    "#lst=lst.sort()\n",
    "print(lst)\n",
    "def train_model(model):\n",
    "    since=time.time()\n",
    "    best_model_wts=copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('-'*10 + ' Epoch {}'.format(epoch) + '-'*10, flush=True)\n",
    "            \n",
    "        for phase in lst:\n",
    "            print(phase)\n",
    "            if phase=='train':\n",
    "                scheduler.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            running_loss=0\n",
    "            running_corrects=0\n",
    "            for data in dataloaders[phase]:\n",
    "                k=k+1;\n",
    "                if(k%100 == 0):\n",
    "                    print(k/100)\n",
    "\n",
    "                # get the inputs\n",
    "                inputs, labels, idx = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs = Variable(inputs)\n",
    "                    labels = Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "\n",
    "                #bs, ncrops, c, h, w = inputs.size()\n",
    "                #inp_chg = inputs.view(-1, c, h, w)\n",
    "                outputs = model(inputs)\t\n",
    "                #outputs = F.tanh(outputs)\n",
    "                #outputs = (outputs+1)/2\n",
    "\n",
    "                #outputs_avg = outputs.view(bs, ncrops, -1).mean(1)\n",
    "                #print(outputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                f = open(\"/home/ashishmenon/openslide_WSI/synth_pretraining/test_doc.txt\",\"a+\")\n",
    "                f.write(str(torch.max(outputs).item()) + \"\\n\" )\n",
    "                f.close()\n",
    "\n",
    "                f = open(\"/home/ashishmenon/openslide_WSI/synth_pretraining/test_classes.txt\",\"a+\")\n",
    "                f.write(str(preds.item()) + \"\\n\" )\n",
    "                f.close()\n",
    "\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                #print('running loss',running_loss)\n",
    "            epoch_acc = (running_corrects.double()) / dataset_sizes[phase]\n",
    "\n",
    "            print('{} resnet-18-Acc: {:.4f}'.format(\n",
    "                    phase, epoch_acc))\n",
    "            print(running_corrects)\n",
    "            print(dataset_sizes[phase])\n",
    "\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('testing complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "\n",
    "    return model\n",
    "   \n",
    "\n",
    "\n",
    "d='/home/ashishmenon/openslide_WSI/synth_pretraining/trained.pth'\n",
    "\n",
    "fd=pathlib.Path(d)\n",
    "\n",
    "\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "\n",
    "if (fd.exists ()):\n",
    "    print('Model loading')\n",
    "    model_ft = model_ft.to(device)\n",
    "    if (device.type == 'cuda') and (ngpu > 1):\n",
    "        model_ft = nn.DataParallel(model_ft, list(range(ngpu)))\n",
    "    model_ft.load_state_dict(torch.load(d))\n",
    "    print('Model loaded')\n",
    "\n",
    "\n",
    "model_conv = train_model(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6114, 0.8601, 0.7593],\n",
      "         [0.4912, 0.6661, 0.0395]],\n",
      "\n",
      "        [[0.0482, 0.8588, 0.5801],\n",
      "         [0.8671, 0.2377, 0.8419]],\n",
      "\n",
      "        [[0.5581, 0.2066, 0.7577],\n",
      "         [0.8969, 0.0351, 0.0335]],\n",
      "\n",
      "        [[0.2962, 0.3896, 0.1435],\n",
      "         [0.4134, 0.8845, 0.0913]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([[0.6114, 0.8601, 0.7593],\n",
       "        [0.8671, 0.8588, 0.8419],\n",
       "        [0.8969, 0.2066, 0.7577],\n",
       "        [0.4134, 0.8845, 0.1435]]),\n",
       "indices=tensor([[0, 0, 0],\n",
       "        [1, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 1, 0]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand(4,2,3)\n",
    "print(x)\n",
    "torch.max(x.data,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "classes={ 0:'cancer' , 1:'normal'}\n",
    "\n",
    "_, preds = torch.max(x.data, 1)\n",
    "preds.view(-1).numpy()\n",
    "preds\n",
    "xy=list((preds.view(-1).numpy()))\n",
    "for i in range(len(xy)):\n",
    "    print(xy[i])\n",
    "    \n",
    "for i in range(len(xy)):\n",
    "    f = open(\"./test.txt\",\"a+\")\n",
    "    f.write(str(xy[i])+ \"\\n\" )\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
