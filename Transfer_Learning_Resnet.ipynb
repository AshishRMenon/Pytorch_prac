{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms,models\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ants', 'bees']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"\n",
    "    Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "    def __init__(self,root,tranf):\n",
    "        super(ImageFolderWithPaths,self).__init__(root,tranf)\n",
    "    # override the __getitem__ method. this is the method that dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super().__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        imgname= path.split('/')[-1]\n",
    "        #print(f\"path {path} index {index}\")\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,imgname))\n",
    "        return tuple_with_path\n",
    "\n",
    "# EXAMPLE USAGE:\n",
    "# instantiate the dataset and dataloader\n",
    "\n",
    "batchsize=4\n",
    "\n",
    "dataroot='./hymenoptera_data/'\n",
    "data_transforms={ \n",
    "                 'train': transforms.Compose([transforms.RandomResizedCrop(224), \n",
    "                                              transforms.RandomHorizontalFlip(),\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                             ]),\n",
    "                 'val':   transforms.Compose([transforms.Resize(256), \n",
    "                                              transforms.CenterCrop(224),\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                             ]),\n",
    "                }\n",
    "\n",
    "datasets_reqd={x: ImageFolderWithPaths(os.path.join(dataroot,x), data_transforms[x]) for x in ['train','val']}\n",
    "\n",
    "dataloader={ x: torch.utils.data.DataLoader(datasets_reqd[x], batch_size=batchsize, num_workers=4 , shuffle=True) for x in ['train','val']}\n",
    "\n",
    "\n",
    "datalength= { x : len(datasets_reqd[x]) for x in ['train','val']}\n",
    "\n",
    "\n",
    "classes=datasets_reqd['train'].classes\n",
    "\n",
    "device=torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "for inputs, labels , path, imgname in dataloader['train']:\n",
    "    # use the above variables freely\n",
    "    #print(labels, paths)\n",
    "    #print((imgname))\n",
    "    with open(\"data_anam1.txt\", \"a+\") as f: \n",
    "        f.write(str(imgname))\n",
    "        f.write(str(random.randint(0,len(dataloader))))\n",
    "        f.write('\\n')\n",
    "#     dataiter = iter(dataloader)\n",
    "#     batch = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.76625192 -0.34169392  1.79144308  0.7826047 ]] [[-5.09961752e-01  1.28872071e+00 -4.60608098e-01  1.01767849e-03]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array([-1.76625192, -0.34169392,  1.79144308,  0.7826047 ]),\n",
       "  array([-5.09961752e-01,  1.28872071e+00, -4.60608098e-01,  1.01767849e-03]))]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=np.random.randn(1, 4)\n",
    "b=np.random.randn(1, 4)\n",
    "print(a,b)\n",
    "list(zip(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531979952_bde12b3bc0.jpg\n",
      "-\n",
      "531979952\n",
      "\n",
      "\n",
      "662541407_ff8db781e7.jpg\n",
      "-\n",
      "662541407\n",
      "\n",
      "\n",
      "6240338_93729615ec.jpg\n",
      "-\n",
      "6240338\n",
      "\n",
      "\n",
      "459694881_ac657d3187.jpg\n",
      "-\n",
      "459694881\n",
      "\n",
      "\n",
      "1262877379_64fcada201.jpg\n",
      "-\n",
      "1262877379\n",
      "\n",
      "\n",
      "2019439677_2db655d361.jpg\n",
      "-\n",
      "2019439677\n",
      "\n",
      "\n",
      "196430254_46bd129ae7.jpg\n",
      "-\n",
      "196430254\n",
      "\n",
      "\n",
      "49375974_e28ba6f17e.jpg\n",
      "-\n",
      "49375974\n",
      "\n",
      "\n",
      "822537660_caf4ba5514.jpg\n",
      "-\n",
      "822537660\n",
      "\n",
      "\n",
      "2601176055_8464e6aa71.jpg\n",
      "-\n",
      "2601176055\n",
      "\n",
      "\n",
      "506249836_717b73f540.jpg\n",
      "-\n",
      "506249836\n",
      "\n",
      "\n",
      "1092977343_cb42b38d62.jpg\n",
      "-\n",
      "1092977343\n",
      "\n",
      "\n",
      "2330918208_8074770c20.jpg\n",
      "-\n",
      "2330918208\n",
      "\n",
      "\n",
      "2861002136_52c7c6f708.jpg\n",
      "-\n",
      "2861002136\n",
      "\n",
      "\n",
      "649026570_e58656104b.jpg\n",
      "-\n",
      "649026570\n",
      "\n",
      "\n",
      "1097045929_1753d1c765.jpg\n",
      "-\n",
      "1097045929\n",
      "\n",
      "\n",
      "1286984635_5119e80de1.jpg\n",
      "-\n",
      "1286984635\n",
      "\n",
      "\n",
      "1924473702_daa9aacdbe.jpg\n",
      "-\n",
      "1924473702\n",
      "\n",
      "\n",
      "36900412_92b81831ad.jpg\n",
      "-\n",
      "36900412\n",
      "\n",
      "\n",
      "1030023514_aad5c608f9.jpg\n",
      "-\n",
      "1030023514\n",
      "\n",
      "\n",
      "2683605182_9d2a0c66cf.jpg\n",
      "-\n",
      "2683605182\n",
      "\n",
      "\n",
      "2345177635_caf07159b3.jpg\n",
      "-\n",
      "2345177635\n",
      "\n",
      "\n",
      "1808777855_2a895621d7.jpg\n",
      "-\n",
      "1808777855\n",
      "\n",
      "\n",
      "trap-jaw-ant-insect-bg.jpg\n",
      "-\n",
      "trap-jaw-ant-insect-bg.jpg\n",
      "\n",
      "\n",
      "1693954099_46d4c20605.jpg\n",
      "-\n",
      "1693954099\n",
      "\n",
      "\n",
      "1917341202_d00a7f9af5.jpg\n",
      "-\n",
      "1917341202\n",
      "\n",
      "\n",
      "0013035.jpg\n",
      "-\n",
      "0013035.jpg\n",
      "\n",
      "\n",
      "3074585407_9854eb3153.jpg\n",
      "-\n",
      "3074585407\n",
      "\n",
      "\n",
      "2728759455_ce9bb8cd7a.jpg\n",
      "-\n",
      "2728759455\n",
      "\n",
      "\n",
      "201790779_527f4c0168.jpg\n",
      "-\n",
      "201790779\n",
      "\n",
      "\n",
      "2493379287_4100e1dacc.jpg\n",
      "-\n",
      "2493379287\n",
      "\n",
      "\n",
      "938946700_ca1c669085.jpg\n",
      "-\n",
      "938946700\n",
      "\n",
      "\n",
      "541630764_dbd285d63c.jpg\n",
      "-\n",
      "541630764\n",
      "\n",
      "\n",
      "2031225713_50ed499635.jpg\n",
      "-\n",
      "2031225713\n",
      "\n",
      "\n",
      "24335309_c5ea483bb8.jpg\n",
      "-\n",
      "24335309\n",
      "\n",
      "\n",
      "465133211_80e0c27f60.jpg\n",
      "-\n",
      "465133211\n",
      "\n",
      "\n",
      "334167043_cbd1adaeb9.jpg\n",
      "-\n",
      "334167043\n",
      "\n",
      "\n",
      "2756397428_1d82a08807.jpg\n",
      "-\n",
      "2756397428\n",
      "\n",
      "\n",
      "2288481644_83ff7e4572.jpg\n",
      "-\n",
      "2288481644\n",
      "\n",
      "\n",
      "198508668_97d818b6c4.jpg\n",
      "-\n",
      "198508668\n",
      "\n",
      "\n",
      "560966032_988f4d7bc4.jpg\n",
      "-\n",
      "560966032\n",
      "\n",
      "\n",
      "154124431_65460430f2.jpg\n",
      "-\n",
      "154124431\n",
      "\n",
      "\n",
      "98391118_bdb1e80cce.jpg\n",
      "-\n",
      "98391118\n",
      "\n",
      "\n",
      "382971067_0bfd33afe0.jpg\n",
      "-\n",
      "382971067\n",
      "\n",
      "\n",
      "hormiga_co_por.jpg\n",
      "-\n",
      "hormiga\n",
      "\n",
      "\n",
      "2792000093_e8ae0718cf.jpg\n",
      "-\n",
      "2792000093\n",
      "\n",
      "\n",
      "178538489_bec7649292.jpg\n",
      "-\n",
      "178538489\n",
      "\n",
      "\n",
      "1508176360_2972117c9d.jpg\n",
      "-\n",
      "1508176360\n",
      "\n",
      "\n",
      "339670531_94b75ae47a.jpg\n",
      "-\n",
      "339670531\n",
      "\n",
      "\n",
      "188552436_605cc9b36b.jpg\n",
      "-\n",
      "188552436\n",
      "\n",
      "\n",
      "29494643_e3410f0d37.jpg\n",
      "-\n",
      "29494643\n",
      "\n",
      "\n",
      "149244013_c529578289.jpg\n",
      "-\n",
      "149244013\n",
      "\n",
      "\n",
      "1093831624_fb5fbe2308.jpg\n",
      "-\n",
      "1093831624\n",
      "\n",
      "\n",
      "3100226504_c0d4f1e3f1.jpg\n",
      "-\n",
      "3100226504\n",
      "\n",
      "\n",
      "148715752_302c84f5a4.jpg\n",
      "-\n",
      "148715752\n",
      "\n",
      "\n",
      "2384149906_2cd8b0b699.jpg\n",
      "-\n",
      "2384149906\n",
      "\n",
      "\n",
      "2470492904_837e97800d.jpg\n",
      "-\n",
      "2470492904\n",
      "\n",
      "\n",
      "873076652_eb098dab2d.jpg\n",
      "-\n",
      "873076652\n",
      "\n",
      "\n",
      "95238259_98470c5b10.jpg\n",
      "-\n",
      "95238259\n",
      "\n",
      "\n",
      "1360291657_dc248c5eea.jpg\n",
      "-\n",
      "1360291657\n",
      "\n",
      "\n",
      "174142798_e5ad6d76e0.jpg\n",
      "-\n",
      "174142798\n",
      "\n",
      "\n",
      "2288450226_a6e96e8fdf.jpg\n",
      "-\n",
      "2288450226\n",
      "\n",
      "\n",
      "2610833167_79bf0bcae5.jpg\n",
      "-\n",
      "2610833167\n",
      "\n",
      "\n",
      "506249802_207cd979b4.jpg\n",
      "-\n",
      "506249802\n",
      "\n",
      "\n",
      "Ant_1.jpg\n",
      "-\n",
      "Ant\n",
      "\n",
      "\n",
      "374435068_7eee412ec4.jpg\n",
      "-\n",
      "374435068\n",
      "\n",
      "\n",
      "1099452230_d1949d3250.jpg\n",
      "-\n",
      "1099452230\n",
      "\n",
      "\n",
      "2634617358_f32fd16bea.jpg\n",
      "-\n",
      "2634617358\n",
      "\n",
      "\n",
      "154600396_53e1252e52.jpg\n",
      "-\n",
      "154600396\n",
      "\n",
      "\n",
      "3090975720_71f12e6de4.jpg\n",
      "-\n",
      "3090975720\n",
      "\n",
      "\n",
      "1489674356_09d48dde0a.jpg\n",
      "-\n",
      "1489674356\n",
      "\n",
      "\n",
      "446296270_d9e8b93ecf.jpg\n",
      "-\n",
      "446296270\n",
      "\n",
      "\n",
      "392382602_1b7bed32fa.jpg\n",
      "-\n",
      "392382602\n",
      "\n",
      "\n",
      "132826773_dbbcb117b9.jpg\n",
      "-\n",
      "132826773\n",
      "\n",
      "\n",
      "36439863_0bec9f554f.jpg\n",
      "-\n",
      "36439863\n",
      "\n",
      "\n",
      "28847243_e79fe052cd.jpg\n",
      "-\n",
      "28847243\n",
      "\n",
      "\n",
      "2610838525_fe8e3cae47.jpg\n",
      "-\n",
      "2610838525\n",
      "\n",
      "\n",
      "258217966_d9d90d18d3.jpg\n",
      "-\n",
      "258217966\n",
      "\n",
      "\n",
      "2265825502_fff99cfd2d.jpg\n",
      "-\n",
      "2265825502\n",
      "\n",
      "\n",
      "201558278_fe4caecc76.jpg\n",
      "-\n",
      "201558278\n",
      "\n",
      "\n",
      "795000156_a9900a4a71.jpg\n",
      "-\n",
      "795000156\n",
      "\n",
      "\n",
      "359928878_b3b418c728.jpg\n",
      "-\n",
      "359928878\n",
      "\n",
      "\n",
      "1660097129_384bf54490.jpg\n",
      "-\n",
      "1660097129\n",
      "\n",
      "\n",
      "2765347790_da6cf6cb40.jpg\n",
      "-\n",
      "2765347790\n",
      "\n",
      "\n",
      "318052216_84dff3f98a.jpg\n",
      "-\n",
      "318052216\n",
      "\n",
      "\n",
      "460372577_f2f6a8c9fc.jpg\n",
      "-\n",
      "460372577\n",
      "\n",
      "\n",
      "129236073_0985e91c7d.jpg\n",
      "-\n",
      "129236073\n",
      "\n",
      "\n",
      "279113587_b4843db199.jpg\n",
      "-\n",
      "279113587\n",
      "\n",
      "\n",
      "408393566_b5b694119b.jpg\n",
      "-\n",
      "408393566\n",
      "\n",
      "\n",
      "2801728106_833798c909.jpg\n",
      "-\n",
      "2801728106\n",
      "\n",
      "\n",
      "2397446847_04ef3cd3e1.jpg\n",
      "-\n",
      "2397446847\n",
      "\n",
      "\n",
      "205835650_e6f2614bee.jpg\n",
      "-\n",
      "205835650\n",
      "\n",
      "\n",
      "2321139806_d73d899e66.jpg\n",
      "-\n",
      "2321139806\n",
      "\n",
      "\n",
      "2477324698_3d4b1b1cab.jpg\n",
      "-\n",
      "2477324698\n",
      "\n",
      "\n",
      "162603798_40b51f1654.jpg\n",
      "-\n",
      "162603798\n",
      "\n",
      "\n",
      "1225872729_6f0856588f.jpg\n",
      "-\n",
      "1225872729\n",
      "\n",
      "\n",
      "formica.jpeg\n",
      "-\n",
      "formica.jpeg\n",
      "\n",
      "\n",
      "760568592_45a52c847f.jpg\n",
      "-\n",
      "760568592\n",
      "\n",
      "\n",
      "384191229_5779cf591b.jpg\n",
      "-\n",
      "384191229\n",
      "\n",
      "\n",
      "3044402684_3853071a87.jpg\n",
      "-\n",
      "3044402684\n",
      "\n",
      "\n",
      "17209602_fe5a5a746f.jpg\n",
      "-\n",
      "17209602\n",
      "\n",
      "\n",
      "586041248_3032e277a9.jpg\n",
      "-\n",
      "586041248\n",
      "\n",
      "\n",
      "484293231_e53cfc0c89.jpg\n",
      "-\n",
      "484293231\n",
      "\n",
      "\n",
      "518773929_734dbc5ff4.jpg\n",
      "-\n",
      "518773929\n",
      "\n",
      "\n",
      "2538361678_9da84b77e3.jpg\n",
      "-\n",
      "2538361678\n",
      "\n",
      "\n",
      "196057951_63bf063b92.jpg\n",
      "-\n",
      "196057951\n",
      "\n",
      "\n",
      "535522953_308353a07c.jpg\n",
      "-\n",
      "535522953\n",
      "\n",
      "\n",
      "2358061370_9daabbd9ac.jpg\n",
      "-\n",
      "2358061370\n",
      "\n",
      "\n",
      "537309131_532bfa59ea.jpg\n",
      "-\n",
      "537309131\n",
      "\n",
      "\n",
      "132511197_0b86ad0fff.jpg\n",
      "-\n",
      "132511197\n",
      "\n",
      "\n",
      "998118368_6ac1d91f81.jpg\n",
      "-\n",
      "998118368\n",
      "\n",
      "\n",
      "226951206_d6bf946504.jpg\n",
      "-\n",
      "226951206\n",
      "\n",
      "\n",
      "20935278_9190345f6b.jpg\n",
      "-\n",
      "20935278\n",
      "\n",
      "\n",
      "2445215254_51698ff797.jpg\n",
      "-\n",
      "2445215254\n",
      "\n",
      "\n",
      "1295655112_7813f37d21.jpg\n",
      "-\n",
      "1295655112\n",
      "\n",
      "\n",
      "92663402_37f379e57a.jpg\n",
      "-\n",
      "92663402\n",
      "\n",
      "\n",
      "ant photos.jpg\n",
      "-\n",
      "ant photos.jpg\n",
      "\n",
      "\n",
      "478701318_bbd5e557b8.jpg\n",
      "-\n",
      "478701318\n",
      "\n",
      "\n",
      "774440991_63a4aa0cbe.jpg\n",
      "-\n",
      "774440991\n",
      "\n",
      "\n",
      "2580598377_a4caecdb54.jpg\n",
      "-\n",
      "2580598377\n",
      "\n",
      "\n",
      "1473187633_63ccaacea6.jpg\n",
      "-\n",
      "1473187633\n",
      "\n",
      "\n",
      "3030189811_01d095b793.jpg\n",
      "-\n",
      "3030189811\n",
      "\n",
      "\n",
      "472288710_2abee16fa0.jpg\n",
      "-\n",
      "472288710\n",
      "\n",
      "\n",
      "245647475_9523dfd13e.jpg\n",
      "-\n",
      "245647475\n",
      "\n",
      "\n",
      "522104315_5d3cb2758e.jpg\n",
      "-\n",
      "522104315\n",
      "\n",
      "\n",
      "760526046_547e8b381f.jpg\n",
      "-\n",
      "760526046\n",
      "\n",
      "\n",
      "275429470_b2d7d9290b.jpg\n",
      "-\n",
      "275429470\n",
      "\n",
      "\n",
      "45472593_bfd624f8dc.jpg\n",
      "-\n",
      "45472593\n",
      "\n",
      "\n",
      "365759866_b15700c59b.jpg\n",
      "-\n",
      "365759866\n",
      "\n",
      "\n",
      "512164029_c0a66b8498.jpg\n",
      "-\n",
      "512164029\n",
      "\n",
      "\n",
      "2625499656_e3415e374d.jpg\n",
      "-\n",
      "2625499656\n",
      "\n",
      "\n",
      "2651621464_a2fa8722eb.jpg\n",
      "-\n",
      "2651621464\n",
      "\n",
      "\n",
      "224655713_3956f7d39a.jpg\n",
      "-\n",
      "224655713\n",
      "\n",
      "\n",
      "2495722465_879acf9d85.jpg\n",
      "-\n",
      "2495722465\n",
      "\n",
      "\n",
      "507288830_f46e8d4cb2.jpg\n",
      "-\n",
      "507288830\n",
      "\n",
      "\n",
      "513545352_fd3e7c7c5d.jpg\n",
      "-\n",
      "513545352\n",
      "\n",
      "\n",
      "354167719_22dca13752.jpg\n",
      "-\n",
      "354167719\n",
      "\n",
      "\n",
      "kurokusa.jpg\n",
      "-\n",
      "kurokusa.jpg\n",
      "\n",
      "\n",
      "403746349_71384f5b58.jpg\n",
      "-\n",
      "403746349\n",
      "\n",
      "\n",
      "3006264892_30e9cced70.jpg\n",
      "-\n",
      "3006264892\n",
      "\n",
      "\n",
      "2645107662_b73a8595cc.jpg\n",
      "-\n",
      "2645107662\n",
      "\n",
      "\n",
      "533848102_70a85ad6dd.jpg\n",
      "-\n",
      "533848102\n",
      "\n",
      "\n",
      "469333327_358ba8fe8a.jpg\n",
      "-\n",
      "469333327\n",
      "\n",
      "\n",
      "342438950_a3da61deab.jpg\n",
      "-\n",
      "342438950\n",
      "\n",
      "\n",
      "82852639_52b7f7f5e3.jpg\n",
      "-\n",
      "82852639\n",
      "\n",
      "\n",
      "2551813042_8a070aeb2b.jpg\n",
      "-\n",
      "2551813042\n",
      "\n",
      "\n",
      "150013791_969d9a968b.jpg\n",
      "-\n",
      "150013791\n",
      "\n",
      "\n",
      "2405441001_b06c36fa72.jpg\n",
      "-\n",
      "2405441001\n",
      "\n",
      "\n",
      "2638074627_6b3ae746a0.jpg\n",
      "-\n",
      "2638074627\n",
      "\n",
      "\n",
      "522415432_2218f34bf8.jpg\n",
      "-\n",
      "522415432\n",
      "\n",
      "\n",
      "2781170484_5d61835d63.jpg\n",
      "-\n",
      "2781170484\n",
      "\n",
      "\n",
      "2959730355_416a18c63c.jpg\n",
      "-\n",
      "2959730355\n",
      "\n",
      "\n",
      "21399619_3e61e5bb6f.jpg\n",
      "-\n",
      "21399619\n",
      "\n",
      "\n",
      "1269756697_0bce92cdab.jpg\n",
      "-\n",
      "1269756697\n",
      "\n",
      "\n",
      "957233405_25c1d1187b.jpg\n",
      "-\n",
      "957233405\n",
      "\n",
      "\n",
      "452462695_40a4e5b559.jpg\n",
      "-\n",
      "452462695\n",
      "\n",
      "\n",
      "9715481_b3cb4114ff.jpg\n",
      "-\n",
      "9715481\n",
      "\n",
      "\n",
      "424873399_47658a91fb.jpg\n",
      "-\n",
      "424873399\n",
      "\n",
      "\n",
      "175998972.jpg\n",
      "-\n",
      "175998972.jpg\n",
      "\n",
      "\n",
      "886401651_f878e888cd.jpg\n",
      "-\n",
      "886401651\n",
      "\n",
      "\n",
      "444532809_9e931e2279.jpg\n",
      "-\n",
      "444532809\n",
      "\n",
      "\n",
      "2477349551_e75c97cf4d.jpg\n",
      "-\n",
      "2477349551\n",
      "\n",
      "\n",
      "2467959963_a7831e9ff0.jpg\n",
      "-\n",
      "2467959963\n",
      "\n",
      "\n",
      "167890289_dd5ba923f3.jpg\n",
      "-\n",
      "167890289\n",
      "\n",
      "\n",
      "termite-vs-ant.jpg\n",
      "-\n",
      "termite-vs-ant.jpg\n",
      "\n",
      "\n",
      "2037437624_2d7bce461f.jpg\n",
      "-\n",
      "2037437624\n",
      "\n",
      "\n",
      "Nepenthes_rafflesiana_ant.jpg\n",
      "-\n",
      "Nepenthes\n",
      "\n",
      "\n",
      "266644509_d30bb16a1b.jpg\n",
      "-\n",
      "266644509\n",
      "\n",
      "\n",
      "522163566_fec115ca66.jpg\n",
      "-\n",
      "522163566\n",
      "\n",
      "\n",
      "2528444139_fa728b0f5b.jpg\n",
      "-\n",
      "2528444139\n",
      "\n",
      "\n",
      "2707440199_cd170bd512.jpg\n",
      "-\n",
      "2707440199\n",
      "\n",
      "\n",
      "969455125_58c797ef17.jpg\n",
      "-\n",
      "969455125\n",
      "\n",
      "\n",
      "540889389_48bb588b21.jpg\n",
      "-\n",
      "540889389\n",
      "\n",
      "\n",
      "460874319_0a45ab4d05.jpg\n",
      "-\n",
      "460874319\n",
      "\n",
      "\n",
      "3030772428_8578335616.jpg\n",
      "-\n",
      "3030772428\n",
      "\n",
      "\n",
      "swiss-army-ant.jpg\n",
      "-\n",
      "swiss-army-ant.jpg\n",
      "\n",
      "\n",
      "2652877533_a564830cbf.jpg\n",
      "-\n",
      "2652877533\n",
      "\n",
      "\n",
      "452462677_7be43af8ff.jpg\n",
      "-\n",
      "452462677\n",
      "\n",
      "\n",
      "7759525_1363d24e88.jpg\n",
      "-\n",
      "7759525\n",
      "\n",
      "\n",
      "3079610310_ac2d0ae7bc.jpg\n",
      "-\n",
      "3079610310\n",
      "\n",
      "\n",
      "2292213964_ca51ce4bef.jpg\n",
      "-\n",
      "2292213964\n",
      "\n",
      "\n",
      "707895295_009cf23188.jpg\n",
      "-\n",
      "707895295\n",
      "\n",
      "\n",
      "69639610_95e0de17aa.jpg\n",
      "-\n",
      "69639610\n",
      "\n",
      "\n",
      "67270775_e9fdf77e9d.jpg\n",
      "-\n",
      "67270775\n",
      "\n",
      "\n",
      "1095476100_3906d8afde.jpg\n",
      "-\n",
      "1095476100\n",
      "\n",
      "\n",
      "1804095607_0341701e1c.jpg\n",
      "-\n",
      "1804095607\n",
      "\n",
      "\n",
      "2722592222_258d473e17.jpg\n",
      "-\n",
      "2722592222\n",
      "\n",
      "\n",
      "841049277_b28e58ad05.jpg\n",
      "-\n",
      "841049277\n",
      "\n",
      "\n",
      "2908916142_a7ac8b57a8.jpg\n",
      "-\n",
      "2908916142\n",
      "\n",
      "\n",
      "474806473_ca6caab245.jpg\n",
      "-\n",
      "474806473\n",
      "\n",
      "\n",
      "army-ants-red-picture.jpg\n",
      "-\n",
      "army-ants-red-picture.jpg\n",
      "\n",
      "\n",
      "196658222_3fffd79c67.jpg\n",
      "-\n",
      "196658222\n",
      "\n",
      "\n",
      "2265824718_2c96f485da.jpg\n",
      "-\n",
      "2265824718\n",
      "\n",
      "\n",
      "476347960_52edd72b06.jpg\n",
      "-\n",
      "476347960\n",
      "\n",
      "\n",
      "543417860_b14237f569.jpg\n",
      "-\n",
      "543417860\n",
      "\n",
      "\n",
      "208702903_42fb4d9748.jpg\n",
      "-\n",
      "208702903\n",
      "\n",
      "\n",
      "39747887_42df2855ee.jpg\n",
      "-\n",
      "39747887\n",
      "\n",
      "\n",
      "2962405283_22718d9617.jpg\n",
      "-\n",
      "2962405283\n",
      "\n",
      "\n",
      "1368913450_e146e2fb6d.jpg\n",
      "-\n",
      "1368913450\n",
      "\n",
      "\n",
      "424119020_6d57481dab.jpg\n",
      "-\n",
      "424119020\n",
      "\n",
      "\n",
      "5650366_e22b7e1065.jpg\n",
      "-\n",
      "5650366\n",
      "\n",
      "\n",
      "196757565_326437f5fe.jpg\n",
      "-\n",
      "196757565\n",
      "\n",
      "\n",
      "421515404_e87569fd8b.jpg\n",
      "-\n",
      "421515404\n",
      "\n",
      "\n",
      "2364597044_3c3e3fc391.jpg\n",
      "-\n",
      "2364597044\n",
      "\n",
      "\n",
      "1807583459_4fe92b3133.jpg\n",
      "-\n",
      "1807583459\n",
      "\n",
      "\n",
      "1691282715_0addfdf5e8.jpg\n",
      "-\n",
      "1691282715\n",
      "\n",
      "\n",
      "466430434_4000737de9.jpg\n",
      "-\n",
      "466430434\n",
      "\n",
      "\n",
      "2278278459_6b99605e50.jpg\n",
      "-\n",
      "2278278459\n",
      "\n",
      "\n",
      "MehdiabadiAnt2_600.jpg\n",
      "-\n",
      "MehdiabadiAnt2\n",
      "\n",
      "\n",
      "470127037_513711fd21.jpg\n",
      "-\n",
      "470127037\n",
      "\n",
      "\n",
      "2227611847_ec72d40403.jpg\n",
      "-\n",
      "2227611847\n",
      "\n",
      "\n",
      "2822388965_f6dca2a275.jpg\n",
      "-\n",
      "2822388965\n",
      "\n",
      "\n",
      "473618094_8ffdcab215.jpg\n",
      "-\n",
      "473618094\n",
      "\n",
      "\n",
      "342758693_c56b89b6b6.jpg\n",
      "-\n",
      "342758693\n",
      "\n",
      "\n",
      "2486746709_c43cec0e42.jpg\n",
      "-\n",
      "2486746709\n",
      "\n",
      "\n",
      "475961153_b8c13fd405.jpg\n",
      "-\n",
      "475961153\n",
      "\n",
      "\n",
      "1799726602_8580867f71.jpg\n",
      "-\n",
      "1799726602\n",
      "\n",
      "\n",
      "85112639_6e860b0469.jpg\n",
      "-\n",
      "85112639\n",
      "\n",
      "\n",
      "150801171_cd86f17ed8.jpg\n",
      "-\n",
      "150801171\n",
      "\n",
      "\n",
      "2452236943_255bfd9e58.jpg\n",
      "-\n",
      "2452236943\n",
      "\n",
      "\n",
      "132478121_2a430adea2.jpg\n",
      "-\n",
      "132478121\n",
      "\n",
      "\n",
      "1232245714_f862fbe385.jpg\n",
      "-\n",
      "1232245714\n",
      "\n",
      "\n",
      "6743948_2b8c096dda.jpg\n",
      "-\n",
      "6743948\n",
      "\n",
      "\n",
      "892108839_f1aad4ca46.jpg\n",
      "-\n",
      "892108839\n",
      "\n",
      "\n",
      "90179376_abc234e5f4.jpg\n",
      "-\n",
      "90179376\n",
      "\n",
      "\n",
      "255434217_1b2b3fe0a4.jpg\n",
      "-\n",
      "255434217\n",
      "\n",
      "\n",
      "16838648_415acd9e3f.jpg\n",
      "-\n",
      "16838648\n",
      "\n",
      "\n",
      "39672681_1302d204d1.jpg\n",
      "-\n",
      "39672681\n",
      "\n",
      "\n",
      "116570827_e9c126745d.jpg\n",
      "-\n",
      "116570827\n",
      "\n",
      "\n",
      "150801003_3390b73135.jpg\n",
      "-\n",
      "150801003\n",
      "\n",
      "\n",
      "2704348794_eb5d5178c2.jpg\n",
      "-\n",
      "2704348794\n",
      "\n",
      "\n",
      "450057712_771b3bfc91.jpg\n",
      "-\n",
      "450057712\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457457145_5f86eb7e9c.jpg\n",
      "-\n",
      "457457145\n",
      "\n",
      "\n",
      "509247772_2db2d01374.jpg\n",
      "-\n",
      "509247772\n",
      "\n",
      "\n",
      "386190770_672743c9a7.jpg\n",
      "-\n",
      "386190770\n",
      "\n",
      "\n",
      "2486729079_62df0920be.jpg\n",
      "-\n",
      "2486729079\n",
      "\n",
      "\n",
      "VietnameseAntMimicSpider.jpg\n",
      "-\n",
      "VietnameseAntMimicSpider.jpg\n",
      "\n",
      "\n",
      "207947948_3ab29d7207.jpg\n",
      "-\n",
      "207947948\n",
      "\n",
      "\n",
      "512863248_43c8ce579b.jpg\n",
      "-\n",
      "512863248\n",
      "\n",
      "\n",
      "6240329_72c01e663e.jpg\n",
      "-\n",
      "6240329\n",
      "\n",
      "\n",
      "2053200300_8911ef438a.jpg\n",
      "-\n",
      "2053200300\n",
      "\n",
      "\n",
      "2710368626_cb42882dc8.jpg\n",
      "-\n",
      "2710368626\n",
      "\n",
      "\n",
      "684133190_35b62c0c1d.jpg\n",
      "-\n",
      "684133190\n",
      "\n",
      "\n",
      "2617161745_fa3ebe85b4.jpg\n",
      "-\n",
      "2617161745\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "x=[1,2,3,4]\n",
    "for inputs, labels , path, imgname in dataloader['train']:\n",
    "    for i in range(inputs.shape[0]):\n",
    "        print(imgname[i])\n",
    "        print('-')\n",
    "        print(str(imgname[i]).split('_')[0])\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95238259_98470c5b10.jpg [ 0.7011744  -0.54666746 -0.3887371   0.7581178 ]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-1259ec74ae99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "for inputs, labels , path, imgname in dataloader['train']:\n",
    "    \n",
    "    loss=torch.randn(1,4)\n",
    "    loss=loss.numpy()\n",
    "    for i in range(4):\n",
    "        print(imgname[i],loss[i]ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3675,  0.8482,  0.2686, -0.3149, -1.3644,  1.8511, -1.3294,  2.6268,\n",
       "         -1.3342,  0.2552,  1.4071, -0.8320,  1.7215, -0.1387, -0.7022,  0.0047]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.randn(1,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names\n",
    "\n",
    "def imgshow(img):\n",
    "    im=img.numpy().transpose((1,2,0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    im= std*im + mean\n",
    "    plt.imshow(im)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images,labels= iter(dataloader['train']).next()\n",
    "images=torchvision.utils.make_grid(images)\n",
    "imgshow(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[(1, 2), (3, 4), (5, 6), (7, 8), (9, 10)]'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[1,3,5,7,9]\n",
    "y=[2,4,6,8,10]\n",
    "str(list(zip(x,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[1,2,3,4]\n",
    "y=['abc', 'def', 'ghi', 'jkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['def'], dtype='<U3')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imagename=[]\n",
    "Predictions=[]\n",
    "Actual=[]\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler , num_epochs=25):\n",
    "    since=time.time()\n",
    "    best_model_wts=copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    i=0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase=='train':\n",
    "                scheduler.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            running_loss=0\n",
    "            running_corrects=0\n",
    "            for images , labels , paths, imgname in dataloader[phase]:\n",
    "            \n",
    "                images=images.to(device)\n",
    "                labels=labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    \n",
    "                    outputs=model(images)\n",
    "                    _,predictions=torch.max(outputs,1)\n",
    "                    loss=criterion(outputs,labels)\n",
    "                    if phase=='train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss+=loss.item()*images.size(0)\n",
    "                running_corrects+=torch.sum(predictions == labels.data)\n",
    "                for j in range(images.shape[0]):\n",
    "                    Imagename.append((str(list(imgname)[j])))\n",
    "                    Predictions.append(str(classes[predictions.numpy()[j]]))\n",
    "                    Actual.append(str(classes[labels.numpy()[j]]))\n",
    "                    \n",
    "            epoch_loss=running_loss/datalength[phase]\n",
    "            epoch_acc=running_corrects.double()/datalength[phase]\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            \n",
    "            if phase=='val' and epoch_acc>best_acc:\n",
    "                best_acc=epoch_acc\n",
    "                best_model_wts=copy.deepcopy(model.state_dict())\n",
    "    model.load_state_dict(best_model_wts)    \n",
    "    return model\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4886 Acc: 0.7705\n",
      "val Loss: 0.2076 Acc: 0.9085\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "model_conv = train_model(model_ft, criterion, optimizer_ft,\n",
    "                         exp_lr_scheduler, num_epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Images': Imagename,\n",
    "                  'Predicted': Predictions , 'Actual': Actual})\n",
    "\n",
    "\n",
    "writer = pd.ExcelWriter('Predictions.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "workbook=writer.book\n",
    "worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "format = workbook.add_format({'text_wrap': True})\n",
    "\n",
    "# Setting the format but not setting the column width.\n",
    "worksheet.set_column('A:B', None, format)\n",
    "\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients=[]\n",
    "p=subprocess.Popen('find ./ -name \"*.jpg\" |cut -d \"_\" -f 1 | uniq ', stdout=subprocess.PIPE ,shell=True)\n",
    "out=p.communicate()[0] \n",
    "for line in out.splitlines():\n",
    "    patients.append(line.decode(\"utf-8\").split('./')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets,models\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "import os\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datalaoding, dataset preparation , transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T          = {'train' : transforms.Compose([ transforms.RandomResizedCrop(224),\n",
    "                                            transforms.RandomHorizontalFlip(),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "                                            ]),\n",
    "             \n",
    "            'val':  transforms.Compose([ transforms.RandomResizedCrop(224),\n",
    "                                            transforms.RandomHorizontalFlip(),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "                                            ]) \n",
    "\n",
    "             }\n",
    "root= './hymenoptera_data'\n",
    "dataset_reqd = { x : datasets.ImageFolder(os.path.join(root,x), T[x]) for x in ['train','val']}\n",
    "dataloader_reqd= { x : torch.utils.data.DataLoader(dataset_reqd[x], batch_size=4 , num_workers=4, shuffle=True) for x in ['train', 'val']}\n",
    "            \n",
    "datalength= { x : len(dataset_reqd[x]) for x in ['train' , 'val']}\n",
    "\n",
    "image,labels= iter(dataloader_reqd['train']).next()\n",
    "labels          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def imageshow(im):\n",
    "    im_np= im.numpy()\n",
    "    im_np= np.transpose(im_np, (1,2,0))\n",
    "    im_np=im_np*0.5 + 0.5 \n",
    "    plt.imshow(im_np)\n",
    "images,labels = iter(dataloader_reqd['train']).next()\n",
    "images=torchvision.utils.make_grid(images)\n",
    "imageshow(images)\n",
    "#images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define network if exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(model , scheduler , optim, criterion):\n",
    "    best_model=copy.deepcopy(model.state_dict())\n",
    "    best_acc=0\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['train','val']:\n",
    "            if phase=='train':\n",
    "                scheduler.step()\n",
    "                model.train()\n",
    "            if phase == 'val':\n",
    "                model.eval\n",
    "            running_loss=0\n",
    "            running_correctness=0\n",
    "            \n",
    "            for images,labels in dataloader_reqd[phase]:\n",
    "                images=images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optim.zero_grad()\n",
    "            \n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    output = model(images)\n",
    "                    loss = criterion(output,labels)\n",
    "                    _,predictions= torch.max(output,1)\n",
    "                       \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optim.step()\n",
    "                running_loss+=loss*images.shape(0)\n",
    "                running_correctness += torch.sum(predictions==labels)\n",
    "            epoch_loss= running_loss/datalength[phase]\n",
    "            epoch_correctness= running_correctness.double()/datalength[phase]\n",
    "            print(\"{} , {} \" .format(epoch_loss,epoch_correctness))\n",
    "            \n",
    "            if phase=='val' and epoch_correctness > best_acc:\n",
    "                best_acc=epoch_correctness\n",
    "                best_model=copy.deepcopy(model.state_dict())\n",
    "                \n",
    "    model.load_state_dict(best_model)\n",
    "    return model\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d={}\n",
    "d['a'] =1 \n",
    "d['b'] = 2\n",
    "d['c'] =1\n",
    "keys=[]\n",
    "values=[]\n",
    "for i in d.keys():\n",
    "    keys.append(i)\n",
    "    values.append(d[i])\n",
    "values\n",
    "#d.values().count(1)\n",
    "list(d.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=['cancer', 'normal','cancer', 'normal','cancer', 'cancer','cancer', 'cancer',]\n",
    "a.count('cancer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./list_val/KIRP_mod5/images_pred.txt\", \"rb\") as fp:\n",
    "    im_pred=pickle.load(fp)\n",
    "\n",
    "with open(\"./list_val/KIRP_mod5//predictions.txt\", \"rb\") as fp:\n",
    "    pred=pickle.load(fp)\n",
    "\n",
    "with open(\"./list_val/KIRP_mod5/Groundtruth_patchwise.txt\", \"rb\") as fp:\n",
    "    actual=pickle.load(fp)\n",
    "\n",
    "with open(\"./list_val/KIRP_mod5/cancer_count_pred.txt\", \"rb\") as fp:\n",
    "    cancer_count_pred=pickle.load(fp)\n",
    "\n",
    "with open(\"./list_val/KIRP_mod5/normal_count_pred.txt\", \"rb\") as fp:\n",
    "    normal_count_pred=pickle.load(fp)\n",
    "\n",
    "with open(\"./list_val/KIRP_mod5/cancer_count_actual.txt\", \"rb\") as fp:\n",
    "    cancer_count_actual=pickle.load(fp)\n",
    "    \n",
    "with open(\"./list_val/KIRP_mod5/normal_count_actual.txt\", \"rb\") as fp:\n",
    "    normal_count_actual=pickle.load(fp)\n",
    "\n",
    "with open(\"./list_val/KIRP_mod5/cancer_count_pred.txt\", \"rb\") as fp:\n",
    "    cancer_count_pred=pickle.load(fp)\n",
    "\n",
    "with open(\"./list_val/KIRP_mod5/Groundtruth_slidewise.txt\", \"rb\") as fp:\n",
    "    GT_patchwise=pickle.load(fp)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCGA-A4-A57E-11A-01-TS1.1CC7185A-BACC-45FF-BE39-93E25FB9996A\n",
      "TCGA-A4-A5Y0-11A-01-TS1.A819CDA6-6C60-4EB5-B19C-60563B1A2A02\n",
      "TCGA-A4-A6HP-11A-01-TS1.FCACEAF8-6C12-4B5F-8CEA-5FE0A1485676\n",
      "TCGA-B3-3925-11A-01-TS1.59c23c72-802f-4ad2-b35b-9075e3eeb2b3\n",
      "TCGA-GL-A59T-11A-01-TS1.C10B5D1F-A12A-47B5-BE85-E8D649C1C2E4\n",
      "TCGA-Y8-A8RZ-11A-01-TS1.67491A24-94D0-494B-9742-39678D009C3C\n"
     ]
    }
   ],
   "source": [
    "list(zip(cancer_count_actual,normal_count_actual))\n",
    "list(zip(cancer_count_pred,normal_count_pred))\n",
    "len(GT_patchwise)\n",
    "\n",
    "for i in range(len(cancer_count_actual)):\n",
    "    if (normal_count_actual[i]>cancer_count_actual[i]) and (cancer_count_pred[i]>normal_count_pred[i]):\n",
    "        print(im_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCGA-A4-A57E-11A-01-TS1.1CC7185A-BACC-45FF-BE39-93E25FB9996A\n",
      "370 0\n",
      "34 336\n",
      "TCGA-A4-A5Y0-11A-01-TS1.A819CDA6-6C60-4EB5-B19C-60563B1A2A02\n",
      "807 0\n",
      "314 493\n",
      "TCGA-A4-A6HP-11A-01-TS1.FCACEAF8-6C12-4B5F-8CEA-5FE0A1485676\n",
      "791 0\n",
      "25 766\n",
      "TCGA-B3-3925-11A-01-TS1.59c23c72-802f-4ad2-b35b-9075e3eeb2b3\n",
      "609 0\n",
      "78 531\n",
      "TCGA-GL-A59T-11A-01-TS1.C10B5D1F-A12A-47B5-BE85-E8D649C1C2E4\n",
      "121 0\n",
      "26 95\n",
      "TCGA-Y8-A8RZ-11A-01-TS1.67491A24-94D0-494B-9742-39678D009C3C\n",
      "193 0\n",
      "44 149\n"
     ]
    }
   ],
   "source": [
    "list(zip(cancer_count_actual,normal_count_actual))\n",
    "list(zip(cancer_count_pred,normal_count_pred))\n",
    "len(GT_patchwise)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCGA-KL-8329-11A-01-TS1.55cef38f-9e3a-47aa-af40-e2b889a8e4a1\n",
      "11224 0\n",
      "4639 6585\n",
      "TCGA-KN-8421-11A-01-TS1.62126a43-93e4-490e-bcc1-df50f4075851\n",
      "2589 0\n",
      "971 1618\n",
      "TCGA-KN-8430-11A-01-TS1.aa5a7373-34cb-445c-ba94-bc37f78537b4\n",
      "5778 0\n",
      "1506 4272\n",
      "TCGA-KO-8405-11A-01-TS1.255ca3a3-1579-4dfa-88c2-6dc70f2e7ac8\n",
      "2912 0\n",
      "1453 1459\n",
      "TCGA-KO-8415-11A-01-TS1.a291096e-6b62-41b7-a571-60fa196357ad\n",
      "4332 0\n",
      "1901 2431\n",
      "TCGA-UW-A7GI-11Z-00-DX1.3D506541-C999-4897-B21B-2211ADB364AE\n",
      "11884 0\n",
      "3804 8080\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cancer_count_actual)):\n",
    "    if (normal_count_actual[i]>cancer_count_actual[i]) and (cancer_count_pred[i]>normal_count_pred[i]):\n",
    "        print(im_pred[i])\n",
    "        print(normal_count_actual[i],cancer_count_actual[i])\n",
    "        print(normal_count_pred[i] ,cancer_count_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCGA-BQ-5886-01A-01-TS1.2ed30241-45a3-4d5c-be14-f4ef6494c02d\n",
      "0 1408\n",
      "837 571\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cancer_count_actual)):\n",
    "    if (normal_count_actual[i]<cancer_count_actual[i]) and (cancer_count_pred[i]<normal_count_pred[i]):\n",
    "        print(im_pred[i])\n",
    "        print(normal_count_actual[i],cancer_count_actual[i])\n",
    "        print(normal_count_pred[i] ,cancer_count_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cancer_count_actual)):\n",
    "    if (normal_count_actual[i]>cancer_count_actual[i]) and (cancer_count_pred[i]>normal_count_pred[i]):\n",
    "        print(im_pred[i])\n",
    "        print(normal_count_actual[i],cancer_count_actual[i])\n",
    "        print(normal_count_pred[i] ,cancer_count_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCGA-KN-8426-01A-01-TS1.e53a4425-2aee-4706-ab5e-c800b2455fa4\n",
      "0 28\n",
      "28 0\n",
      "TCGA-KN-8428-01A-01-BS1.5a59e77e-f8fb-4b0d-ab7d-193b3df684d9\n",
      "0 6729\n",
      "4978 1751\n",
      "TCGA-KN-8432-01A-01-TS1.2ee6adff-a00e-4095-bed4-74882a148f0d\n",
      "0 3123\n",
      "2496 627\n",
      "TCGA-KO-8406-01A-01-TS1.7b3f0605-de4d-4691-a5d5-cee6b1712636\n",
      "0 1240\n",
      "755 485\n",
      "TCGA-UW-A7GJ-01Z-00-DX1.5CA0FD93-E237-4AEC-84D6-0199A62105DE\n",
      "0 17786\n",
      "17088 698\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cancer_count_actual)):\n",
    "    if (normal_count_actual[i]<cancer_count_actual[i]) and (cancer_count_pred[i]<normal_count_pred[i]):\n",
    "        print(im_pred[i])\n",
    "        print(normal_count_actual[i],cancer_count_actual[i])\n",
    "        print(normal_count_pred[i] ,cancer_count_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Images': im_pred,'Predicted_patchwise': pred ,'Actual_patchwise' : actual, 'SLidewise_GT':GT_patchwise , 'Actual (C,N)':list(zip(cancer_count_actual,normal_count_actual)) , 'Predicted (C,N)':list(zip(cancer_count_pred,normal_count_pred))  })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "writer = pd.ExcelWriter('Predictions_KIRP_mod_proper5.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "workbook=writer.book\n",
    "worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "#format = workbook.add_format({'text_wrap': True})\n",
    "format = workbook.add_format({'num_format': '#,##0.00'})\n",
    "# Setting the format but not setting the column width.\n",
    "worksheet.set_column('A:B', None, format)\n",
    "\n",
    "writer.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1000.]], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "x= Variable(1000*torch.ones(1,1),requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-202-620f01ce3afd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cancer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0md_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cancer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0md_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd_pred' is not defined"
     ]
    }
   ],
   "source": [
    "for i in d_pred.keys():\n",
    "    print(d_pred[i].count('cancer'))\n",
    "    print(d_pred[i].count('normal'))\n",
    "    if d_pred[i].count('cancer') > d_pred[i].count('normal'):\n",
    "\n",
    "        patient_pred[i]='cancer'\n",
    "    if d_pred[i].count('cancer') < d_pred[i].count('normal'):\n",
    "        patient_pred[i]='normal'\n",
    "    print(patient_pred[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(cancer_count_actual,normal_count_actual)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import time\n",
    "import functools\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "#import sklearn.datasets\n",
    "\n",
    "import libs as lib\n",
    "import libs.plot\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.autograd import Variable\n",
    "import pdb\n",
    "import gpustat\n",
    "\n",
    "from models.wgan import *\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch import autograd\n",
    "from torch import optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.autograd import grad\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import torch.nn.init as init\n",
    "\n",
    "# lsun lmdb data set can be download via https://github.com/fyu/lsun\n",
    "# 64x64 ImageNet at http://image-net.org/small/download.php\n",
    "DATA_DIR = '/ssd_scratch/cvit/ashish/KIRP_wgan' # Replace your image data path here\n",
    "VAL_DIR = '/ssd_scratch/cvit/ashish/KIRP_wgan'\n",
    "IMAGE_DATA_SET = 'KIRP_wgan' \n",
    "# change this to something else, e.g. 'imagenets' or 'raw' if your data is just a folder of raw images. \n",
    "# Example: \n",
    "# IMAGE_DATA_SET = 'raw'\n",
    "# If you use lmdb, you'll need to write the loader by yourself. Please check load_data function\n",
    "\n",
    "TRAINING_CLASS = ['train'] # IGNORE this if you are NOT training on lsun, or if you want to train on other classes of lsun, then change it accordingly\n",
    "VAL_CLASS = ['valid'] # IGNORE this if you are NOT training on lsun, or if you want to train on other classes of lsun, then change it accordingly\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--ngpu')\n",
    "parser.add_argument('--startiter')\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "ngpu=int(args.ngpu)\n",
    "\n",
    "if len(DATA_DIR) == 0:\n",
    "    raise Exception('Please specify path to data directory in gan_64x64.py!')\n",
    "\n",
    "RESTORE_MODE = False # if True, it will load saved model from OUT_PATH and continue to train\n",
    "START_ITER = int(args.startiter) # starting iteration \n",
    "OUTPUT_PATH = './output/' # output path where result (.e.g drawing images, cost, chart) will be stored\n",
    "# MODE = 'wgan-gp'\n",
    "DIM = 256 # Model dimensionality\n",
    "CRITIC_ITERS = 5 # How many iterations to train the critic for\n",
    "GENER_ITERS = 1\n",
    "N_GPUS = 4 # Number of GPUs\n",
    "BATCH_SIZE = 20# Batch size. Must be a multiple of N_GPUS\n",
    "END_ITER = 75000 # How many iterations to train for\n",
    "LAMBDA = 10 # Gradient penalty lambda hyperparameter\n",
    "OUTPUT_DIM = 256*256*3 # Number of pixels in each image\n",
    "\n",
    "def showMemoryUsage(device=1):\n",
    "    gpu_stats = gpustat.GPUStatCollection.new_query()\n",
    "    item = gpu_stats.jsonify()[\"gpus\"][device]\n",
    "    print('Used/total: ' + \"{}/{}\".format(item[\"memory.used\"], item[\"memory.total\"]))\n",
    "\n",
    "device1 = torch.device(\"cpu\")\n",
    "def weights_init(m):\n",
    "    if isinstance(m, MyConvo2d): \n",
    "        if m.conv.weight is not None:\n",
    "            if m.he_init:\n",
    "                init.kaiming_uniform_(m.conv.weight)\n",
    "            else:\n",
    "                init.xavier_uniform_(m.conv.weight)\n",
    "        if m.conv.bias is not None:\n",
    "            init.constant_(m.conv.bias, 0.0)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        if m.weight is not None:\n",
    "            init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            init.constant_(m.bias, 0.0)\n",
    "\n",
    "def load_data(path_to_folder, classes):\n",
    "    data_transform = transforms.Compose([\n",
    "                 transforms.Scale(256),\n",
    "                 transforms.CenterCrop(256),\n",
    "                 transforms.ToTensor(),\n",
    "                 transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])\n",
    "                ])\n",
    "    if IMAGE_DATA_SET == 'lsun':\n",
    "        dataset =  datasets.LSUN(path_to_folder, classes=classes, transform=data_transform)\n",
    "    else:\n",
    "        dataset = datasets.ImageFolder(root=path_to_folder,transform=data_transform)\n",
    "    dataset_loader = torch.utils.data.DataLoader(dataset,batch_size=BATCH_SIZE, shuffle=True, num_workers=5)\n",
    "    return dataset_loader\n",
    "\n",
    "def training_data_loader():\n",
    "    return load_data(DATA_DIR, TRAINING_CLASS) \n",
    "\n",
    "def val_data_loader():\n",
    "    return load_data(VAL_DIR, VAL_CLASS) \n",
    "\n",
    "def calc_gradient_penalty(netD, real_data, fake_data):\n",
    "    rd=real_data.clone().cpu()\n",
    "    bs=rd.shape[0]\n",
    "    alpha = torch.rand(bs, 1)\n",
    "    alpha = alpha.expand(bs, int(real_data.nelement()/bs)).contiguous()\n",
    "    alpha = alpha.view(bs, 3, DIM, DIM)\n",
    "    alpha = alpha.to(device)\n",
    "    \n",
    "    fake_data = fake_data.view(bs, 3, DIM, DIM)\n",
    "    interpolates = alpha * real_data.detach() + ((1 - alpha) * fake_data.detach())\n",
    "\n",
    "    interpolates = interpolates.to(device)\n",
    "    interpolates.requires_grad_(True)\n",
    "\n",
    "    disc_interpolates = netD(interpolates)\n",
    "\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones(disc_interpolates.size()).to(device),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "    gradients = gradients.view(gradients.size(0), -1)                              \n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n",
    "    return gradient_penalty\n",
    "\n",
    "def generate_image(netG, noise=None):\n",
    "    if noise is None:\n",
    "        noise = gen_rand_noise()\n",
    "\n",
    "    with torch.no_grad():\n",
    "    \tnoisev = noise \n",
    "    samples = netG(noisev)\n",
    "    samples = samples.view(BATCH_SIZE, 3, 256, 256)\n",
    "    samples = samples * 0.5 + 0.5\n",
    "    samples=samples.cpu()\n",
    "    return samples\n",
    "\n",
    "def gen_rand_noise():\n",
    "    noise = torch.randn(BATCH_SIZE, 128)\n",
    "    noise = noise.to(device)\n",
    "\n",
    "    return noise\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda_available else \"cpu\")\n",
    "fixed_noise = torch.randn(BATCH_SIZE, 128).to(device)\n",
    "\n",
    "if RESTORE_MODE:\n",
    "    aG = GoodGenerator().to(device)\n",
    "    if (device.type == 'cuda') and (ngpu > 1):\n",
    "        aG = nn.DataParallel(aG, list(range(ngpu)))\n",
    "    aG.load_state_dict(torch.load(OUTPUT_PATH + \"generator.pth\"))\n",
    "    aD = GoodDiscriminator(out_feat=False).to(device)\n",
    "    if (device.type == 'cuda') and (ngpu > 1):\n",
    "        aD = nn.DataParallel(aD, list(range(ngpu)))\n",
    "    aD.load_state_dict(torch.load(OUTPUT_PATH + \"discriminator.pth\"))\n",
    "    aG_cpu = GoodGenerator()\n",
    "    aG_cpu = nn.DataParallel(aG_cpu)\n",
    "    aG_cpu.load_state_dict(torch.load(OUTPUT_PATH + \"generator.pth\", map_location=device1))\n",
    "else:\n",
    "    aG = GoodGenerator()\n",
    "    aD = GoodDiscriminator(out_feat=False)\n",
    "    aG_cpu = GoodGenerator()\n",
    "    aG.apply(weights_init)\n",
    "    aD.apply(weights_init)\n",
    "    aG_cpu.apply(weights_init)\n",
    "    aG = aG.to(device)\n",
    "    aD = aD.to(device)\n",
    "\n",
    "    if (device.type == 'cuda') and (ngpu > 1):\n",
    "        aG = nn.DataParallel(aG, list(range(ngpu)))\n",
    "        aD = nn.DataParallel(aD, list(range(ngpu)))\n",
    "        aG_cpu = nn.DataParallel(aG_cpu)\n",
    "\n",
    "\n",
    "\n",
    "LR = 1e-4\n",
    "optimizer_g = torch.optim.Adam(aG.parameters(), lr=LR, betas=(0,0.9))\n",
    "optimizer_d = torch.optim.Adam(aD.parameters(), lr=LR, betas=(0,0.9))\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1\n",
    "one = one.to(device)\n",
    "mone = mone.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "writer = SummaryWriter()\n",
    "#Reference: https://github.com/caogang/wgan-gp/blob/master/gan_cifar10.py\n",
    "\n",
    "\"\"\"\n",
    "def train():\n",
    "   \n",
    "    dataloader = training_data_loader()\n",
    "    iteration=0 \n",
    "    for epoch in range(5): \n",
    "        for _, images in enumerate(dataloader):\n",
    "            iteration+=1\n",
    "            start_time = time.time()\n",
    "            print(\"Iter: \" + str(iteration))\n",
    "            start = timer()\n",
    "            #---------------------TRAIN G------------------------\n",
    "            for p in aD.parameters():\n",
    "                p.requires_grad_(False)  # freeze D\n",
    "\n",
    "            gen_cost = None\n",
    "            for i in range(GENER_ITERS):\n",
    "                print(\"Generator iters: \" + str(i))\n",
    "                aG.zero_grad()\n",
    "                noise = gen_rand_noise()\n",
    "                noise.requires_grad_(True)\n",
    "                fake_data = aG(noise)\n",
    "                gen_cost = aD(fake_data)\n",
    "                gen_cost = gen_cost.mean()\n",
    "                gen_cost.backward(mone)\n",
    "                gen_cost = -gen_cost\n",
    "\n",
    "            optimizer_g.step()\n",
    "            end = timer()\n",
    "            print(f'---train G elapsed time: {end - start}')\n",
    "            #---------------------TRAIN D------------------------\n",
    "            for p in aD.parameters():  # reset requires_grad\n",
    "                p.requires_grad_(True)  # they are set to False below in training G\n",
    "            for i in range(CRITIC_ITERS):\n",
    "                print(\"Critic iter: \" + str(i))\n",
    "\n",
    "                start = timer()\n",
    "                aD.zero_grad()\n",
    "\n",
    "                # gen fake data and load real data\n",
    "                noise = gen_rand_noise()\n",
    "                with torch.no_grad():\n",
    "                    noisev = noise  # totally freeze G, training D\n",
    "                fake_data = aG(noisev).detach()\n",
    "                end = timer(); print(f'---gen G elapsed time: {end-start}')\n",
    "                start = timer()\n",
    "                #batch = batch[0] #batch[1] contains labels\n",
    "                imgs = torch.Tensor(images[0])\n",
    "                real_data = imgs.to(device)\n",
    "                #real_data = images.to(device) #TODO: modify load_data for each loading\n",
    "                end = timer(); print(f'---load real imgs elapsed time: {end-start}')\n",
    "                start = timer()\n",
    "\n",
    "                # train with real data\n",
    "                disc_real = aD(real_data)\n",
    "                disc_real = disc_real.mean()\n",
    "\n",
    "                # train with fake data\n",
    "                disc_fake = aD(fake_data)\n",
    "                disc_fake = disc_fake.mean()\n",
    "\n",
    "                #showMemoryUsage(0)\n",
    "                # train with interpolates data\n",
    "                gradient_penalty = calc_gradient_penalty(aD, real_data, fake_data)\n",
    "                #showMemoryUsage(0)\n",
    "\n",
    "                # final disc cost\n",
    "                disc_cost = disc_fake - disc_real + gradient_penalty\n",
    "                disc_cost.backward()\n",
    "                w_dist = disc_fake  - disc_real\n",
    "                optimizer_d.step()\n",
    "                #------------------VISUALIZATION----------\n",
    "                if i == CRITIC_ITERS-1:\n",
    "                    \n",
    "                    writer.add_scalar('data/disc_cost', disc_cost, iteration)\n",
    "                    #writer.add_scalar('data/disc_fake', disc_fake, iteration)\n",
    "                    #writer.add_scalar('data/disc_real', disc_real, iteration)\n",
    "                    writer.add_scalar('data/gradient_pen', gradient_penalty, iteration)\n",
    "                    #writer.add_scalar('data/d_conv_weight_mean', [i for i in aD.children()][0].conv.weight.data.clone().mean(), iteration)\n",
    "                    #writer.add_scalar('data/d_linear_weight_mean', [i for i in aD.children()][-1].weight.data.clone().mean(), iteration)\n",
    "                    #writer.add_scalar('data/fake_data_mean', fake_data.mean())\n",
    "                    #writer.add_scalar('data/real_data_mean', real_data.mean())\n",
    "                    #if iteration %200==99:\n",
    "                    #    paramsD = aD.named_parameters()\n",
    "                    #    for name, pD in paramsD:\n",
    "                    #        writer.add_histogram(\"D.\" + name, pD.clone().data.cpu().numpy(), iteration)\n",
    "                    \n",
    "                    if iteration %200==199:\n",
    "                        body_model = [i for i in aD.children()][0]\n",
    "                        layer1 = body_model.conv1.conv\n",
    "                        xyz = layer1.weight.data.clone()\n",
    "                        tensor = xyz.cpu()\n",
    "                        tensors = torchvision.utils.make_grid(tensor, nrow=8,padding=1)\n",
    "                        writer.add_image('D/conv1', tensors, iteration)\n",
    "                    \n",
    "\n",
    "                end = timer(); print(f'---train D elapsed time: {end-start}')\n",
    "        #---------------VISUALIZATION---------------------\n",
    "\n",
    "            writer.add_scalar('data/gen_cost', gen_cost, iteration)\n",
    "            lib.plot.plot(OUTPUT_PATH + 'time', time.time() - start_time)\n",
    "            lib.plot.plot(OUTPUT_PATH + 'train_disc_cost', disc_cost.cpu().data.numpy())\n",
    "            lib.plot.plot(OUTPUT_PATH + 'train_gen_cost', gen_cost.cpu().data.numpy())\n",
    "            lib.plot.plot(OUTPUT_PATH + 'wasserstein_distance', w_dist.cpu().data.numpy())\n",
    "            if iteration % 200 == 199:\n",
    "                \n",
    "                val_loader = val_data_loader() \n",
    "                dev_disc_costs = []\n",
    "                for _, images in enumerate(val_loader):\n",
    "                    imgs = torch.Tensor(images[0])\n",
    "                    imgs = imgs.to(device)\n",
    "                    with torch.no_grad():\n",
    "                        imgs_v = imgs\n",
    "\n",
    "                    D = aD(imgs_v)\n",
    "                    _dev_disc_cost = -D.mean().cpu().data.numpy()\n",
    "                    dev_disc_costs.append(_dev_disc_cost)\n",
    "                lib.plot.plot(OUTPUT_PATH + 'dev_disc_cost.png', np.mean(dev_disc_costs))\n",
    "                lib.plot.flush()\t\n",
    "                \n",
    "                torch.save(aG.state_dict(),OUTPUT_PATH + \"generator.pth\")\n",
    "                torch.save(aD.state_dict(), OUTPUT_PATH + \"discriminator.pth\")\n",
    "                aG_cpu.load_state_dict(torch.load(OUTPUT_PATH + \"generator.pth\", map_location='cpu'))\n",
    "                gen_images = generate_image(aG_cpu.cuda(), fixed_noise)\n",
    "                torchvision.utils.save_image(gen_images, OUTPUT_PATH + 'samples_{}.png'.format(iteration), nrow=8, padding=2)\n",
    "                grid_images = torchvision.utils.make_grid(gen_images, nrow=8, padding=2)\n",
    "                writer.add_image('images', grid_images, iteration)\n",
    "        #----------------------Save model----------------------\n",
    "                \n",
    "            lib.plot.tick()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def train():\n",
    "    gen_cost_prev = Variable(10000*torch.ones(1,1),requires_grad=True)\n",
    "    disc_cost_prev = Variable(10000*torch.ones(1,1),requires_grad=True)\n",
    "    dataloader = training_data_loader() \n",
    "    dataiter = iter(dataloader)\n",
    "    for iteration in range(START_ITER, END_ITER):\n",
    "        start_time = time.time()\n",
    "        print(\"Iter: \" + str(iteration))\n",
    "        start = timer()\n",
    "        #---------------------TRAIN G------------------------\n",
    "        for p in aD.parameters():\n",
    "            p.requires_grad_(False)  # freeze D\n",
    "\n",
    "        gen_cost = None\n",
    "        for i in range(GENER_ITERS):\n",
    "            print(\"Generator iters: \" + str(i))\n",
    "            aG.zero_grad()\n",
    "            noise = gen_rand_noise()\n",
    "            noise.requires_grad_(True)\n",
    "            fake_data = aG(noise)\n",
    "            gen_cost = aD(fake_data)\n",
    "            gen_cost = gen_cost.mean()\n",
    "            gen_cost.backward(mone)\n",
    "            gen_cost = -gen_cost\n",
    "      \n",
    "        optimizer_g.step()\n",
    "        end = timer()\n",
    "        gen_cost_present = gen_cost\n",
    "        \n",
    "        if (gen_cost_present.detach().cpu().numpy())< (gen_cost_prev.detach().cpu().numpy()):\n",
    "                gen_cost_prev=gen_cost_present \n",
    "                print(\"Gen Model Saving\")\n",
    "                torch.save(aG.state_dict(),OUTPUT_PATH + \"generator.pth\")\n",
    "                print(\"Gen Model Saved\")\n",
    "        print(f'---train G elapsed time: {end - start}')\n",
    "        #---------------------TRAIN D------------------------\n",
    "        for p in aD.parameters():  # reset requires_grad\n",
    "            p.requires_grad_(True)  # they are set to False below in training G\n",
    "        for i in range(CRITIC_ITERS):\n",
    "            torch.cuda.empty_cache()\n",
    "            print(\"Critic iter: \" + str(i))\n",
    "            \n",
    "            start = timer()\n",
    "            aD.zero_grad()\n",
    "\n",
    "            # gen fake data and load real data\n",
    "            noise = gen_rand_noise()\n",
    "            with torch.no_grad():\n",
    "                noisev = noise  # totally freeze G, training D\n",
    "            fake_data = aG(noisev).detach()\n",
    "            end = timer(); print(f'---gen G elapsed time: {end-start}')\n",
    "            start = timer()\n",
    "            batch = next(dataiter, None)\n",
    "            if batch is None:\n",
    "                dataiter = iter(dataloader)\n",
    "                batch = dataiter.next()\n",
    "            batch = batch[0] #batch[1] contains labels\n",
    "            real_data = batch.to(device) #TODO: modify load_data for each loading\n",
    "            end = timer(); print(f'---load real imgs elapsed time: {end-start}')\n",
    "            start = timer()\n",
    "\n",
    "            # train with real data\n",
    "            disc_real = aD(real_data)\n",
    "            #disc_real = Variable(disc_real,volatile=True)\n",
    "            disc_real = disc_real.mean()\n",
    "\n",
    "            # train with fake data\n",
    "            disc_fake = aD(fake_data)\n",
    "            #disc_fake = Variable(disc_fake,volatile=True)\n",
    "            disc_fake = disc_fake.mean()\n",
    "\n",
    "            #showMemoryUsage(0)\n",
    "            # train with interpolates data\n",
    "            gradient_penalty = calc_gradient_penalty(aD, real_data, fake_data)\n",
    "            #showMemoryUsage(0)\n",
    "\n",
    "            # final disc cost\n",
    "            disc_cost = disc_fake - disc_real + gradient_penalty\n",
    "            disc_cost.backward()\n",
    "            w_dist = disc_fake  - disc_real\n",
    "            optimizer_d.step()\n",
    "            disc_cost_present = disc_cost\n",
    "            print(\"Disc_Cost : {}\".format(disc_cost.cpu()))\n",
    "            if (disc_cost_present.detach().cpu().numpy()) < (disc_cost_prev.detach().cpu().numpy()):\n",
    "                disc_cost_prev=disc_cost_present \n",
    "                print(\" Disc Model Saving\")\n",
    "                torch.save(aD.state_dict(),OUTPUT_PATH + \"discriminator.pth\")\n",
    "                print(\" Disc Model Saved\")\n",
    "            #------------------VISUALIZATION----------\n",
    "            if i == CRITIC_ITERS-1:\n",
    "                writer.add_scalar('data/disc_cost', disc_cost, iteration)\n",
    "                #writer.add_scalar('data/disc_fake', disc_fake, iteration)\n",
    "                #writer.add_scalar('data/disc_real', disc_real, iteration)\n",
    "                writer.add_scalar('data/gradient_pen', gradient_penalty, iteration)\n",
    "                #writer.add_scalar('data/d_conv_weight_mean', [i for i in aD.children()][0].conv.weight.data.clone().mean(), iteration)\n",
    "                #writer.add_scalar('data/d_linear_weight_mean', [i for i in aD.children()][-1].weight.data.clone().mean(), iteration)\n",
    "                #writer.add_scalar('data/fake_data_mean', fake_data.mean())\n",
    "                #writer.add_scalar('data/real_data_mean', real_data.mean())\n",
    "                #if iteration %200==99:\n",
    "                #    paramsD = aD.named_parameters()\n",
    "                #    for name, pD in paramsD:\n",
    "                #        writer.add_histogram(\"D.\" + name, pD.clone().data.cpu().numpy(), iteration)\n",
    "                \"\"\"\n",
    "                if iteration %200==199:\n",
    "                    body_model = [i for i in aD.children()][0]\n",
    "                    layer1 = body_model.conv\n",
    "                    xyz = layer1.weight.data.clone()\n",
    "                    tensor = xyz.cpu()\n",
    "                    tensors = torchvision.utils.make_grid(tensor, nrow=8,padding=1)\n",
    "                    writer.add_image('D/conv1', tensors, iteration)\n",
    "               \"\"\"\n",
    "            end = timer(); print(f'---train D elapsed time: {end-start}')\n",
    "        #---------------VISUALIZATION---------------------\n",
    "        writer.add_scalar('data/gen_cost', gen_cost, iteration)\n",
    "\n",
    "        lib.plot.plot(OUTPUT_PATH + 'time', time.time() - start_time)\n",
    "        lib.plot.plot(OUTPUT_PATH + 'train_disc_cost', disc_cost.cpu().data.numpy())\n",
    "        lib.plot.plot(OUTPUT_PATH + 'train_gen_cost', gen_cost.cpu().data.numpy())\n",
    "        lib.plot.plot(OUTPUT_PATH + 'wasserstein_distance', w_dist.cpu().data.numpy())\n",
    "        if iteration % 200 == 199:\n",
    "            \"\"\"\n",
    "            val_loader = val_data_loader() \n",
    "            dev_disc_costs = []\n",
    "            for _, images in enumerate(val_loader):\n",
    "                imgs = torch.Tensor(images[0])\n",
    "               \timgs = imgs.to(device)\n",
    "                with torch.no_grad():\n",
    "            \t    imgs_v = imgs\n",
    "\n",
    "                D = aD(imgs_v)\n",
    "                _dev_disc_cost = -D.mean().cpu().data.numpy()\n",
    "                dev_disc_costs.append(_dev_disc_cost)\n",
    "            lib.plot.plot(OUTPUT_PATH + 'dev_disc_cost.png', np.mean(dev_disc_costs))\n",
    "            lib.plot.flush()\n",
    "            \"\"\"\t\n",
    "            torch.save(aG.state_dict(),OUTPUT_PATH + \"generator.pth\")\n",
    "            torch.save(aD.state_dict(), OUTPUT_PATH + \"discriminator.pth\")\n",
    "            #aG_cpu.load_state_dict(torch.load(OUTPUT_PATH + \"generator.pth\", map_location=device1))\n",
    "            gen_images = generate_image(aG, fixed_noise)\n",
    "            torchvision.utils.save_image(gen_images, OUTPUT_PATH + 'samples_{}.png'.format(iteration), nrow=8, padding=2)\n",
    "            grid_images = torchvision.utils.make_grid(gen_images.cpu(), nrow=8, padding=2)\n",
    "            writer.add_image('images', grid_images.cpu(), iteration)\n",
    "\t#----------------------Save model----------------------\n",
    "            \n",
    "        lib.plot.tick()\n",
    "\n",
    "train()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
